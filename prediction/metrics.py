import numpy as np
import pandas as pd
import logging
import traceback
from sklearn.metrics import f1_score, precision_score, recall_score, classification_report

from app.utils.date_utils import format_date

logger = logging.getLogger(__name__)

def calculate_interval_averages_and_scores(predictions, business_days, min_window_size=5):
    """
    ë‹¤ìŒ ë°˜ì›” ê¸°ê°„ì— ëŒ€í•´ ë‹¤ì–‘í•œ í¬ê¸°ì˜ êµ¬ê°„ë³„ í‰ê·  ê°€ê²©ì„ ê³„ì‚°í•˜ê³  ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ëŠ” í•¨ìˆ˜
    - ë°˜ì›” ì „ì²´ ì˜ì—…ì¼ ìˆ˜ì— ë§ì¶° ìœˆë„ìš° í¬ê¸° ë²”ìœ„ ì¡°ì •
    - global_rank ë°©ì‹: ëª¨ë“  êµ¬ê°„ì„ ë¹„êµí•´ ì „ì—­ì ìœ¼ë¡œ ê°€ì¥ ì €ë ´í•œ êµ¬ê°„ì— ì ìˆ˜ ë¶€ì—¬
    
    Parameters:
    -----------
    predictions : list
        ë‚ ì§œë³„ ì˜ˆì¸¡ ê°€ê²© ì •ë³´ (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)
    business_days : list
        ë‹¤ìŒ ë°˜ì›”ì˜ ì˜ì—…ì¼ ëª©ë¡
    min_window_size : int
        ìµœì†Œ ê³ ë ¤í•  ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 3)
    
    Returns:
    -----------
    tuple
        (êµ¬ê°„ë³„ í‰ê·  ê°€ê²© ì •ë³´, êµ¬ê°„ë³„ ì ìˆ˜ ì •ë³´, ë¶„ì„ ì¶”ê°€ ì •ë³´)
    """
    import numpy as np
    
    # ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ë¡œ ì •ë¦¬
    predictions_dict = {pred['Date']: pred['Prediction'] for pred in predictions if pred['Date'] in business_days}
    
    # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì˜ì—…ì¼ ëª©ë¡
    sorted_days = sorted(business_days)
    
    # ë‹¤ìŒ ë°˜ì›” ì´ ì˜ì—…ì¼ ìˆ˜ ê³„ì‚°
    total_days = len(sorted_days)
    
    # ìµœì†Œ ìœˆë„ìš° í¬ê¸°ì™€ ìµœëŒ€ ìœˆë„ìš° í¬ê¸° ì„¤ì • (ìµœëŒ€ëŠ” ë°˜ì›” ì „ì²´ ì¼ìˆ˜)
    max_window_size = total_days
    
    # ê³ ë ¤í•  ëª¨ë“  ìœˆë„ìš° í¬ê¸° ë²”ìœ„ ìƒì„±
    window_sizes = range(min_window_size, max_window_size + 1)
    
    print(f"ë‹¤ìŒ ë°˜ì›” ì˜ì—…ì¼: {total_days}ì¼, ê³ ë ¤í•  ìœˆë„ìš° í¬ê¸°: {list(window_sizes)}")
    
    # ê° ìœˆë„ìš° í¬ê¸°ë³„ ê²°ê³¼ ì €ì¥
    interval_averages = {}
    
    # ëª¨ë“  êµ¬ê°„ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_intervals = []
    
    # ê° ìœˆë„ìš° í¬ê¸°ì— ëŒ€í•´ ëª¨ë“  ê°€ëŠ¥í•œ êµ¬ê°„ ê³„ì‚°
    for window_size in window_sizes:
        window_results = []
        
        # ê°€ëŠ¥í•œ ëª¨ë“  ì‹œì‘ì ì— ëŒ€í•´ ìœˆë„ìš° í‰ê·  ê³„ì‚°
        for i in range(len(sorted_days) - window_size + 1):
            interval_days = sorted_days[i:i+window_size]
            
            # ëª¨ë“  ë‚ ì§œì— ì˜ˆì¸¡ ê°€ê²©ì´ ìˆëŠ”ì§€ í™•ì¸
            if all(day in predictions_dict for day in interval_days):
                avg_price = np.mean([predictions_dict[day] for day in interval_days])
                
                interval_info = {
                    'start_date': interval_days[0],
                    'end_date': interval_days[-1],
                    'days': window_size,
                    'avg_price': avg_price,
                    'dates': interval_days.copy()
                }
                
                window_results.append(interval_info)
                all_intervals.append(interval_info)  # ëª¨ë“  êµ¬ê°„ ëª©ë¡ì—ë„ ì¶”ê°€
        
        # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì— ëŒ€í•œ ê²°ê³¼ ì €ì¥ (ì°¸ê³ ìš©)
        if window_results:
            # í‰ê·  ê°€ê²© ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            window_results.sort(key=lambda x: x['avg_price'])
            interval_averages[window_size] = window_results
    
    # êµ¬ê°„ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    interval_scores = {}
    
    # Global Rank ì „ëµ: ëª¨ë“  êµ¬ê°„ì„ í†µí•©í•˜ì—¬ ê°€ê²© ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_intervals.sort(key=lambda x: x['avg_price'])
    
    # ìƒìœ„ 3ê°œ êµ¬ê°„ì—ë§Œ ì ìˆ˜ ë¶€ì—¬ (ì „ì²´ ì¤‘ì—ì„œ)
    for i, interval in enumerate(all_intervals[:min(3, len(all_intervals))]):
        score = 3 - i  # 1ë“±: 3ì , 2ë“±: 2ì , 3ë“±: 1ì 
        
        # êµ¬ê°„ ì‹ë³„ì„ ìœ„í•œ í‚¤ ìƒì„± (ë¬¸ìì—´ í‚¤ë¡œ ë³€ê²½)
        interval_key = f"{format_date(interval['start_date'])}-{format_date(interval['end_date'])}"
        
        # ì ìˆ˜ ì •ë³´ ì €ì¥
        interval_scores[interval_key] = {
            'start_date': format_date(interval['start_date']),  # í˜•ì‹ ì ìš©
            'end_date': format_date(interval['end_date']),      # í˜•ì‹ ì ìš©
            'days': interval['days'],
            'avg_price': interval['avg_price'],
            'dates': [format_date(d) for d in interval['dates']],  # ë‚ ì§œ ëª©ë¡ë„ í˜•ì‹ ì ìš©
            'score': score,
            'rank': i + 1
        }
    
    # ë¶„ì„ ì •ë³´ ì¶”ê°€
    analysis_info = {
        'total_days': total_days,
        'window_sizes': list(window_sizes),
        'total_intervals': len(all_intervals),
        'min_avg_price': min([interval['avg_price'] for interval in all_intervals]) if all_intervals else None,
        'max_avg_price': max([interval['avg_price'] for interval in all_intervals]) if all_intervals else None
    }
    
    # ê²°ê³¼ ì¶œë ¥ (ì°¸ê³ ìš©)
    if interval_scores:
        top_interval = max(interval_scores.values(), key=lambda x: x['score'])
        print(f"\nìµœê³  ì ìˆ˜ êµ¬ê°„: {top_interval['days']}ì¼ êµ¬ê°„ ({format_date(top_interval['start_date'])} ~ {format_date(top_interval['end_date'])})")
        print(f"ì ìˆ˜: {top_interval['score']}, ìˆœìœ„: {top_interval['rank']}, í‰ê· ê°€: {top_interval['avg_price']:.2f}")
    
    return interval_averages, interval_scores, analysis_info

def decide_purchase_interval(interval_scores):
    """
    ì ìˆ˜ê°€ ë¶€ì—¬ëœ êµ¬ê°„ë“¤ ì¤‘ì—ì„œ ìµœì¢… êµ¬ë§¤ êµ¬ê°„ì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    - ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ êµ¬ê°„ ì„ íƒ
    - ë™ì ì¸ ê²½ìš° í‰ê·  ê°€ê²©ì´ ë” ë‚®ì€ êµ¬ê°„ ì„ íƒ
    
    Parameters:
    -----------
    interval_scores : dict
        êµ¬ê°„ë³„ ì ìˆ˜ ì •ë³´
    
    Returns:
    -----------
    dict
        ìµœì¢… ì„ íƒëœ êµ¬ë§¤ êµ¬ê°„ ì •ë³´
    """
    if not interval_scores:
        return None
    
    # ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ êµ¬ê°„ ì„ íƒ
    max_score = max(interval['score'] for interval in interval_scores.values())
    
    # ìµœê³  ì ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë“  êµ¬ê°„ ì°¾ê¸°
    top_intervals = [interval for interval in interval_scores.values() 
                    if interval['score'] == max_score]
    
    # ë™ì ì´ ìˆëŠ” ê²½ìš°, í‰ê·  ê°€ê²©ì´ ë” ë‚®ì€ êµ¬ê°„ ì„ íƒ
    if len(top_intervals) > 1:
        best_interval = min(top_intervals, key=lambda x: x['avg_price'])
        best_interval['selection_reason'] = "ìµœê³  ì ìˆ˜ ì¤‘ ìµœì € í‰ê· ê°€ êµ¬ê°„"
    else:
        best_interval = top_intervals[0]
        best_interval['selection_reason'] = "ìµœê³  ì ìˆ˜ êµ¬ê°„"
    
    return best_interval

def compute_performance_metrics_improved(validation_data, start_day_value):
    """
    ê²€ì¦ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    """
    try:
        # âœ… start_day_valueê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°(None, NaN)ë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
        if start_day_value is None or pd.isna(start_day_value):
            logger.warning("start_day_valueê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None # Noneì„ ë°˜í™˜í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

        if not validation_data or len(validation_data) < 1:
            logger.info("No validation data available - this is normal for pure future predictions")
            return None
        
        # start_day_value ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        if hasattr(start_day_value, 'iloc'):  # pandas Series/DataFrameì¸ ê²½ìš°
            start_val = float(start_day_value.iloc[0] if len(start_day_value) > 0 else start_day_value)
        elif hasattr(start_day_value, 'item'):  # numpy scalarì¸ ê²½ìš°
            start_val = float(start_day_value.item())
        else:
            start_val = float(start_day_value)
        
        # ê²€ì¦ ë°ì´í„°ì—ì„œ ê°’ ì¶”ì¶œ (DataFrame/Seriesë¥¼ numpyë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜)
        actual_vals = [start_val]
        pred_vals = [start_val]
        
        for item in validation_data:
            # actual ê°’ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            actual_val = item['actual']
            if hasattr(actual_val, 'iloc'):  # pandas Series/DataFrameì¸ ê²½ìš°
                actual_val = float(actual_val.iloc[0] if len(actual_val) > 0 else actual_val)
            elif hasattr(actual_val, 'item'):  # numpy scalarì¸ ê²½ìš°
                actual_val = float(actual_val.item())
            else:
                actual_val = float(actual_val)
            actual_vals.append(actual_val)
            
            # prediction ê°’ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            pred_val = item['prediction']
            if hasattr(pred_val, 'iloc'):  # pandas Series/DataFrameì¸ ê²½ìš°
                pred_val = float(pred_val.iloc[0] if len(pred_val) > 0 else pred_val)
            elif hasattr(pred_val, 'item'):  # numpy scalarì¸ ê²½ìš°
                pred_val = float(pred_val.item())
            else:
                pred_val = float(pred_val)
            pred_vals.append(pred_val)
        
        # F1 ì ìˆ˜ ê³„ì‚° (ê° ë‹¨ê³„ë³„ ë¡œê¹… ì¶”ê°€)
        try:
            f1, f1_report = calculate_f1_score(actual_vals, pred_vals)
        except Exception as e:
            logger.error(f"Error in F1 score calculation: {str(e)}")
            f1, f1_report = 0.0, "Error in F1 calculation"
            
        try:
            direction_accuracy = calculate_direction_accuracy(actual_vals, pred_vals)
        except Exception as e:
            logger.error(f"Error in direction accuracy calculation: {str(e)}")
            direction_accuracy = 0.0
            
        try:
            weighted_score, max_score = calculate_direction_weighted_score(actual_vals[1:], pred_vals[1:])
            weighted_score_pct = (weighted_score / max_score) * 100 if max_score > 0 else 0.0
        except Exception as e:
            logger.error(f"Error in weighted score calculation: {str(e)}")
            weighted_score_pct = 0.0
            
        try:
            mape = calculate_mape(actual_vals[1:], pred_vals[1:])
        except Exception as e:
            logger.error(f"Error in MAPE calculation: {str(e)}")
            mape = 0.0
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        cosine_similarity = None
        try:
            if len(actual_vals) > 1:
                # numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                actual_vals_arr = np.array(actual_vals, dtype=float)
                pred_vals_arr = np.array(pred_vals, dtype=float)
                
                diff_actual = np.diff(actual_vals_arr)
                diff_pred = np.diff(pred_vals_arr)
                norm_actual = np.linalg.norm(diff_actual)
                norm_pred = np.linalg.norm(diff_pred)
                if norm_actual > 0 and norm_pred > 0:
                    cosine_similarity = np.dot(diff_actual, diff_pred) / (norm_actual * norm_pred)
        except Exception as e:
            logger.error(f"Error in cosine similarity calculation: {str(e)}")
            cosine_similarity = None
        
        return {
            'f1': float(f1),
            'accuracy': float(direction_accuracy),
            'mape': float(mape),
            'weighted_score': float(weighted_score_pct),
            'cosine_similarity': float(cosine_similarity) if cosine_similarity is not None else None,
            'f1_report': f1_report,
            'validation_points': len(validation_data)
        }
        
    except Exception as e:
        logger.error(f"Error computing improved metrics: {str(e)}")
        return None

def calculate_f1_score(actual, predicted):
    """ë°©í–¥ì„± ì˜ˆì¸¡ì˜ F1 ì ìˆ˜ ê³„ì‚°"""
    # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
    actual = np.array(actual)
    predicted = np.array(predicted)
    
    actual_directions = np.sign(np.diff(actual))
    predicted_directions = np.sign(np.diff(predicted))

    if len(actual_directions) < 2:
        return 0.0, "Insufficient data for classification report"
        
    try:
        # zero_division=0 íŒŒë¼ë¯¸í„° ì¶”ê°€
        f1 = f1_score(actual_directions, predicted_directions, average='macro', zero_division=0)
        report = classification_report(actual_directions, predicted_directions, 
                                    digits=2, zero_division=0)
    except Exception as e:
        logger.error(f"Error in calculating F1 score: {str(e)}")
        return 0.0, "Error in calculation"
        
    return f1, report

def calculate_direction_accuracy(actual, predicted):
    """ë“±ë½ ë°©í–¥ ì˜ˆì¸¡ì˜ ì •í™•ë„ ê³„ì‚°"""
    if len(actual) <= 1:
        return 0.0

    try:
        # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        actual = np.array(actual)
        predicted = np.array(predicted)
        
        actual_directions = np.sign(np.diff(actual))
        predicted_directions = np.sign(np.diff(predicted))
        
        correct_predictions = np.sum(actual_directions == predicted_directions)
        total_predictions = len(actual_directions)
        
        accuracy = (correct_predictions / total_predictions) * 100
        return accuracy
    except Exception as e:
        logger.error(f"Error in calculating direction accuracy: {str(e)}")
        return 0.0
    
def calculate_direction_weighted_score(actual, predicted):
    """ë³€í™”ìœ¨ ê¸°ë°˜ì˜ ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°"""
    if len(actual) <= 1:
        return 0.0, 1.0
        
    try:
        # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        actual = np.array(actual)
        predicted = np.array(predicted)
        
        actual_changes = 100 * np.diff(actual) / actual[:-1]
        predicted_changes = 100 * np.diff(predicted) / predicted[:-1]

        def assign_class(change):
            if change > 6:
                return 1
            elif 4 < change <= 6:
                return 2
            elif 2 < change <= 4:
                return 3
            elif -2 <= change <= 2:
                return 4
            elif -4 <= change < -2:
                return 5
            elif -6 <= change < -4:
                return 6
            else:
                return 7

        actual_classes = np.array([assign_class(x) for x in actual_changes])
        predicted_classes = np.array([assign_class(x) for x in predicted_changes])

        score = 0
        for ac, pc in zip(actual_classes, predicted_classes):
            diff = abs(ac - pc)
            score += max(0, 3 - diff)

        max_score = 3 * len(actual_classes)
        return score, max_score
    except Exception as e:
        logger.error(f"Error in calculating weighted score: {str(e)}")
        return 0.0, 1.0

def calculate_mape(actual, predicted):
    """MAPE ê³„ì‚° í•¨ìˆ˜"""
    try:
        # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        actual = np.array(actual)
        predicted = np.array(predicted)
        
        if len(actual) == 0:
            return 0.0
        # inf ë°©ì§€ë¥¼ ìœ„í•´ 0ì´ ì•„ë‹Œ ê°’ë§Œ ì‚¬ìš©
        mask = actual != 0
        if not np.any(mask):  # any() ëŒ€ì‹  np.any() ì‚¬ìš©
            return 0.0
        return np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
    except Exception as e:
        logger.error(f"Error in MAPE calculation: {str(e)}")
        return 0.0

def calculate_moving_averages_with_history(predictions, historical_data, target_col='MOPJ', windows=[5, 10, 23]):
    """ì˜ˆì¸¡ ë°ì´í„°ì™€ ê³¼ê±° ë°ì´í„°ë¥¼ ëª¨ë‘ í™œìš©í•œ ì´ë™í‰ê·  ê³„ì‚°"""
    try:
        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not predictions or len(predictions) == 0:
            logger.warning("No predictions provided for moving average calculation")
            return {}
            
        if historical_data is None or historical_data.empty:
            logger.warning("No historical data provided for moving average calculation")
            return {}
            
        if target_col not in historical_data.columns:
            logger.warning(f"Target column {target_col} not found in historical data")
            return {}
        
        results = {}
        
        # ì˜ˆì¸¡ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ ë° ì •ë ¬
        try:
            pred_df = pd.DataFrame(predictions) if not isinstance(predictions, pd.DataFrame) else predictions.copy()
            
            # Date ì»¬ëŸ¼ ê²€ì¦ (ëŒ€ì†Œë¬¸ì ëª¨ë‘ ì§€ì›)
            date_col = None
            if 'Date' in pred_df.columns:
                date_col = 'Date'
            elif 'date' in pred_df.columns:
                date_col = 'date'
            else:
                logger.error("Date column not found in predictions (checked both 'Date' and 'date')")
                return {}
                
            pred_df['Date'] = pd.to_datetime(pred_df[date_col])
            pred_df = pred_df.sort_values('Date')
            
            # Prediction ì»¬ëŸ¼ ê²€ì¦ (ëŒ€ì†Œë¬¸ì ëª¨ë‘ ì§€ì›)
            prediction_col = None
            if 'Prediction' in pred_df.columns:
                prediction_col = 'Prediction'
            elif 'prediction' in pred_df.columns:
                prediction_col = 'prediction'
            else:
                logger.error("Prediction column not found in predictions (checked both 'Prediction' and 'prediction')")
                return {}
                
            # Prediction ì»¬ëŸ¼ì„ í‘œì¤€í™”
            if prediction_col != 'Prediction':
                pred_df['Prediction'] = pred_df[prediction_col]
                
        except Exception as e:
            logger.error(f"Error processing prediction data: {str(e)}")
            return {}
        
        # ì˜ˆì¸¡ ì‹œì‘ì¼ í™•ì¸
        prediction_start_date = pred_df['Date'].min()
        logger.info(f"MA calculation - prediction start date: {prediction_start_date}")
        
        # ê³¼ê±° ë°ì´í„°ì—ì„œ íƒ€ê²Ÿ ì—´ ì¶”ì¶œ (ì˜ˆì¸¡ ì‹œì‘ì¼ ì´ì „)
        historical_series = pd.Series(
            data=historical_data.loc[historical_data.index < prediction_start_date, target_col],
            index=historical_data.loc[historical_data.index < prediction_start_date].index
        )
        
        # ìµœê·¼ 30ì¼ë§Œ ì‚¬ìš© (ì´ë™í‰ê·  ê³„ì‚°ì— ì¶©ë¶„)
        historical_series = historical_series.sort_index().tail(30)
        
        # ì˜ˆì¸¡ ë°ì´í„°ì—ì„œ ì‹œë¦¬ì¦ˆ ìƒì„±
        prediction_series = pd.Series(
            data=pred_df['Prediction'].values,
            index=pred_df['Date']
        )
        
        # ê³¼ê±°ì™€ ì˜ˆì¸¡ ë°ì´í„° ê²°í•©
        combined_series = pd.concat([historical_series, prediction_series])
        combined_series = combined_series[~combined_series.index.duplicated(keep='last')]
        combined_series = combined_series.sort_index()
        
        logger.info(f"Combined series for MA: {len(combined_series)} data points "
                   f"({len(historical_series)} historical, {len(prediction_series)} predicted)")
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ ì´ë™í‰ê·  ê³„ì‚°
        for window in windows:
            # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì´ë™í‰ê·  ê³„ì‚°
            rolling_avg = combined_series.rolling(window=window, min_periods=1).mean()
            
            # ì˜ˆì¸¡ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ì¶”ì¶œ
            window_results = []
            
            for i, date in enumerate(pred_df['Date']):
                # í•´ë‹¹ ë‚ ì§œì˜ ì˜ˆì¸¡ ë° ì‹¤ì œê°’
                pred_value = pred_df['Prediction'].iloc[i]
                actual_value = pred_df['Actual'].iloc[i] if 'Actual' in pred_df.columns else None
                
                # í•´ë‹¹ ë‚ ì§œì˜ ì´ë™í‰ê·  ê°’
                ma_value = rolling_avg.loc[date] if date in rolling_avg.index else None
                
                # NaN ê°’ ì²˜ë¦¬
                if pd.isna(pred_value) or np.isnan(pred_value) or np.isinf(pred_value):
                    pred_value = None
                if pd.isna(actual_value) or np.isnan(actual_value) or np.isinf(actual_value):
                    actual_value = None
                if pd.isna(ma_value) or np.isnan(ma_value) or np.isinf(ma_value):
                    ma_value = None
                
                window_results.append({
                    'date': date,
                    'prediction': pred_value,
                    'actual': actual_value,
                    'ma': ma_value
                })
            
            results[f'ma{window}'] = window_results
            logger.info(f"MA{window} calculated: {len(window_results)} data points")
        
        logger.info(f"Moving average calculation completed with {len(results)} windows")
        return results
        
    except Exception as e:
        logger.error(f"Error calculating moving averages with history: {str(e)}")
        logger.error(traceback.format_exc())
        return {}
    
def calculate_prediction_consistency(accumulated_predictions, target_period):
    """
    ë‹¤ìŒ ë°˜ì›”ì— ëŒ€í•œ ì—¬ëŸ¬ ë‚ ì§œì˜ ì˜ˆì¸¡ ì¼ê´€ì„±ì„ ê³„ì‚°
    
    Parameters:
    -----------
    accumulated_predictions: list
        ì—¬ëŸ¬ ë‚ ì§œì— ìˆ˜í–‰í•œ ì˜ˆì¸¡ ê²°ê³¼ ëª©ë¡
    target_period: str
        ë‹¤ìŒ ë°˜ì›” ê¸°ê°„ (ì˜ˆ: "2025-01-SM1")
    
    Returns:
    -----------
    dict: ì¼ê´€ì„± ì ìˆ˜ì™€ ê´€ë ¨ ë©”íŠ¸ë¦­
    """
    import numpy as np
    
    # ë‚ ì§œë³„ ì˜ˆì¸¡ ë°ì´í„° ì¶”ì¶œ
    period_predictions = {}
    
    for prediction in accumulated_predictions:
        # ì•ˆì „í•œ ë°ì´í„° ì ‘ê·¼
        if not isinstance(prediction, dict):
            continue
            
        prediction_date = prediction.get('date')
        next_period = prediction.get('next_semimonthly_period')
        predictions_list = prediction.get('predictions', [])
        
        if next_period != target_period:
            continue
            
        if prediction_date not in period_predictions:
            period_predictions[prediction_date] = []
        
        # predictions_listê°€ ë°°ì—´ì¸ì§€ í™•ì¸
        if not isinstance(predictions_list, list):
            logger.warning(f"predictions_list is not a list for {prediction_date}: {type(predictions_list)}")
            continue
            
        for pred in predictions_list:
            # predê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            if not isinstance(pred, dict):
                logger.warning(f"Prediction item is not a dict for {prediction_date}: {type(pred)}")
                continue
                
            pred_date = pred.get('Date') or pred.get('date')
            pred_value = pred.get('Prediction') or pred.get('prediction')
            
            # ê°’ì´ ìœ íš¨í•œì§€ í™•ì¸
            if pred_date and pred_value is not None:
                period_predictions[prediction_date].append({
                    'date': pred_date,
                    'value': pred_value
                })
    
    # ë‚ ì§œë³„ë¡œ ì •ë ¬
    prediction_dates = sorted(period_predictions.keys())
    
    if len(prediction_dates) < 2:
        return {
            "consistency_score": None,
            "message": "Insufficient prediction data (min 2 required)",
            "period": target_period,
            "dates_count": len(prediction_dates)
        }
    
    # ì¼ê´€ì„± ë¶„ì„ì„ ìœ„í•œ ë‚ ì§œ ë§¤í•‘
    date_predictions = {}
    
    for pred_date in prediction_dates:
        for p in period_predictions[pred_date]:
            target_date = p['date']
            if target_date not in date_predictions:
                date_predictions[target_date] = []
            
            date_predictions[target_date].append({
                'prediction_date': pred_date,
                'value': p['value']
            })
    
    # ê° íƒ€ê²Ÿ ë‚ ì§œë³„ ì˜ˆì¸¡ê°’ ë³€ë™ì„± ê³„ì‚°
    overall_variations = []
    
    for target_date, predictions in date_predictions.items():
        if len(predictions) >= 2:
            # ì˜ˆì¸¡ê°’ ì¶”ì¶œ (None ê°’ í•„í„°ë§)
            values = [p['value'] for p in predictions if p['value'] is not None]
            
            if len(values) < 2:
                continue
                
            # ê°’ì´ ëª¨ë‘ ê°™ì€ ê²½ìš° CVë¥¼ 0ìœ¼ë¡œ ì²˜ë¦¬
            if all(v == values[0] for v in values):
                cv = 0.0
                overall_variations.append(cv)
                continue
            
            mean_value = np.mean(values)
            std_value = np.std(values)
            
            # ë³€ë™ ê³„ìˆ˜ (Coefficient of Variation)
            cv = std_value / abs(mean_value) if mean_value != 0 else float('inf')
            overall_variations.append(cv)
    
    # ì „ì²´ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (ë³€ë™ ê³„ìˆ˜ í‰ê· ì„ 0-100 ì ìˆ˜ë¡œ ë³€í™˜)
    if overall_variations:
        avg_cv = np.mean(overall_variations)
        consistency_score = max(0, min(100, 100 - (avg_cv * 100)))
    else:
        consistency_score = None
    
    # ì‹ ë¢°ë„ ë“±ê¸‰ ë¶€ì—¬
    if consistency_score is not None:
        if consistency_score >= 90:
            grade = "Very High"
        elif consistency_score >= 75:
            grade = "High"
        elif consistency_score >= 60:
            grade = "Medium"
        elif consistency_score >= 40:
            grade = "Low"
        else:
            grade = "Very Low"
    else:
        grade = "Unable to determine"
    
    return {
        "consistency_score": consistency_score,
        "consistency_grade": grade,
        "target_period": target_period,
        "prediction_count": len(prediction_dates),
        "average_variation": avg_cv * 100 if overall_variations else None,
        "message": f"Consistency for period {target_period} based on {len(prediction_dates)} predictions"
    }

# ëˆ„ì  ì˜ˆì¸¡ì˜ êµ¬ë§¤ ì‹ ë¢°ë„ ê³„ì‚° í•¨ìˆ˜ (ì˜¬ë°”ë¥¸ ë²„ì „)
def calculate_accumulated_purchase_reliability(accumulated_predictions):
    """
    ëˆ„ì  ì˜ˆì¸¡ì˜ êµ¬ë§¤ ì‹ ë¢°ë„ ê³„ì‚° (ì˜¬ë°”ë¥¸ ë°©ì‹)
    
    ê° ì˜ˆì¸¡ë§ˆë‹¤ ìƒìœ„ 3ê°œ êµ¬ê°„(1ë“±:3ì , 2ë“±:2ì , 3ë“±:1ì )ì„ ì„ ì •í•˜ê³ ,
    ê°™ì€ êµ¬ê°„ì´ ì—¬ëŸ¬ ì˜ˆì¸¡ì—ì„œ ì„ íƒë˜ë©´ ì ìˆ˜ë¥¼ ëˆ„ì í•˜ì—¬,
    ìµœê³  ëˆ„ì  ì ìˆ˜ êµ¬ê°„ì˜ ì ìˆ˜ / (ì˜ˆì¸¡ íšŸìˆ˜ Ã— 3ì ) Ã— 100%ë¡œ ê³„ì‚°
    
    Returns:
        tuple: (reliability_percentage, debug_info)
    """
    print(f"ğŸ” [RELIABILITY] Function called with {len(accumulated_predictions) if accumulated_predictions else 0} predictions")
    
    if not accumulated_predictions or not isinstance(accumulated_predictions, list):
        print(f"âš ï¸ [RELIABILITY] Invalid input: accumulated_predictions is empty or not a list")
        return 0.0, {}
    
    try:
        prediction_count = len(accumulated_predictions)
        print(f"ğŸ“Š [RELIABILITY] Processing {prediction_count} predictions...")
        
        # ğŸ”‘ êµ¬ê°„ë³„ ëˆ„ì  ì ìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        interval_accumulated_scores = {}
        
        for i, pred in enumerate(accumulated_predictions):
            if not isinstance(pred, dict):
                continue
                
            interval_scores = pred.get('interval_scores', {})
            pred_date = pred.get('date')
            
            if interval_scores and isinstance(interval_scores, dict):
                # ëª¨ë“  êµ¬ê°„ì„ í‰ê·  ê°€ê²© ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ê²©ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                valid_intervals = []
                for score_data in interval_scores.values():
                    if isinstance(score_data, dict) and 'avg_price' in score_data:
                        # ğŸ”§ NaN ê°’ ì²˜ë¦¬ ê°•í™”
                        avg_price = score_data.get('avg_price', 0)
                        if pd.isna(avg_price) or np.isnan(avg_price) or np.isinf(avg_price):
                            avg_price = float('inf')  # NaNì¸ ê²½ìš° ìµœí›„ìˆœìœ„ë¡œ ì„¤ì •
                            score_data['avg_price'] = avg_price
                        valid_intervals.append(score_data)
                
                if valid_intervals:
                    # í‰ê·  ê°€ê²© ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚®ì€ ê°€ê²©ì´ ìš°ì„ )
                    valid_intervals.sort(key=lambda x: x.get('avg_price', float('inf')))
                    
                    # ìƒìœ„ 3ê°œ êµ¬ê°„ì— ì ìˆ˜ ë¶€ì—¬
                    for rank, interval in enumerate(valid_intervals[:3]):
                        score = 3 - rank  # 1ë“±: 3ì , 2ë“±: 2ì , 3ë“±: 1ì 
                        
                        # êµ¬ê°„ ì‹ë³„í‚¤ ìƒì„± (ì‹œì‘ì¼-ì¢…ë£Œì¼)
                        interval_key = f"{interval.get('start_date')} ~ {interval.get('end_date')} ({interval.get('days')}ì¼)"
                        
                        # ëˆ„ì  ì ìˆ˜ ê³„ì‚°
                        if interval_key not in interval_accumulated_scores:
                            interval_accumulated_scores[interval_key] = {
                                'total_score': 0,
                                'appearances': 0,
                                'details': [],
                                'avg_price': interval.get('avg_price', 0),
                                'days': interval.get('days', 0)
                            }
                        
                        interval_accumulated_scores[interval_key]['total_score'] += score
                        interval_accumulated_scores[interval_key]['appearances'] += 1
                        interval_accumulated_scores[interval_key]['details'].append({
                            'date': pred_date,
                            'rank': rank + 1,
                            'score': score,
                            'avg_price': interval.get('avg_price', 0)
                        })
                        
                        print(f"ğŸ“Š [RELIABILITY] ë‚ ì§œ {pred_date}: {rank+1}ë“± {interval_key} â†’ {score}ì  (í‰ê· ê°€: {interval.get('avg_price', 0):.2f})")
        
        # ìµœê³  ëˆ„ì  ì ìˆ˜ êµ¬ê°„ ì°¾ê¸°
        if interval_accumulated_scores:
            best_interval_key = max(interval_accumulated_scores.keys(), 
                                  key=lambda k: interval_accumulated_scores[k]['total_score'])
            best_total_score = interval_accumulated_scores[best_interval_key]['total_score']
            
            # ë§Œì  ê³„ì‚° (ê° ì˜ˆì¸¡ë§ˆë‹¤ ìµœëŒ€ 3ì ì”©)
            max_possible_total_score = prediction_count * 3
            
            # êµ¬ë§¤ ì‹ ë¢°ë„ ê³„ì‚°
            reliability_percentage = (best_total_score / max_possible_total_score) * 100 if max_possible_total_score > 0 else 0.0
            
            # ğŸ”§ NaN ê°’ ì²˜ë¦¬ ê°•í™”
            if pd.isna(reliability_percentage) or np.isnan(reliability_percentage) or np.isinf(reliability_percentage):
                print(f"âš ï¸ [RELIABILITY] NaN/Inf detected in reliability calculation, setting to 0.0")
                reliability_percentage = 0.0
            
            print(f"\nğŸ¯ [RELIABILITY] === êµ¬ê°„ë³„ ëˆ„ì  ì ìˆ˜ ë¶„ì„ ===")
            print(f"ğŸ“Š ì˜ˆì¸¡ íšŸìˆ˜: {prediction_count}ê°œ")
            print(f"ğŸ“Š êµ¬ê°„ë³„ ëˆ„ì  ì ìˆ˜:")
            
            # ëˆ„ì  ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
            sorted_intervals = sorted(interval_accumulated_scores.items(), 
                                    key=lambda x: x[1]['total_score'], reverse=True)
            
            for interval_key, data in sorted_intervals[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                print(f"   - {interval_key}: {data['total_score']}ì  ({data['appearances']}íšŒ ì„ íƒ)")
            
            print(f"\nğŸ† ìµœê³  ì ìˆ˜ êµ¬ê°„: {best_interval_key}")
            print(f"ğŸ† ìµœê³  ëˆ„ì  ì ìˆ˜: {best_total_score}ì ")
            print(f"ğŸ† êµ¬ê°„ ì‹ ë¢°ë„: {best_total_score}/{max_possible_total_score} = {reliability_percentage:.1f}%")
            
            # ë””ë²„ê·¸ ì •ë³´ ìƒì„±
            debug_info = {
                'prediction_count': prediction_count,
                'interval_accumulated_scores': interval_accumulated_scores,
                'best_interval_key': best_interval_key,
                'best_total_score': best_total_score,
                'max_possible_total_score': max_possible_total_score,
                'reliability_percentage': reliability_percentage
            }
            
            return reliability_percentage, debug_info
        else:
            print(f"âš ï¸ [RELIABILITY] No valid interval scores found")
            return 0.0, {}
            
    except Exception as e:
        print(f"Error calculating accumulated purchase reliability: {str(e)}")
        return 0.0, {'error': str(e)} 

def calculate_accumulated_purchase_reliability_with_debug(accumulated_predictions):
    """
    ë””ë²„ê·¸ ì •ë³´ì™€ í•¨ê»˜ ëˆ„ì  ì˜ˆì¸¡ì˜ êµ¬ë§¤ ì‹ ë¢°ë„ ê³„ì‚°
    """
    if not accumulated_predictions or not isinstance(accumulated_predictions, list):
        return 0.0, {}
    
    debug_info = {
        'prediction_count': len(accumulated_predictions),
        'individual_scores': [],
        'total_best_score': 0,
        'max_possible_total_score': 0
    }
    
    try:
        total_best_score = 0
        prediction_count = len(accumulated_predictions)
        
        for i, pred in enumerate(accumulated_predictions):
            if not isinstance(pred, dict):
                continue
                
            pred_date = pred.get('date')
            interval_scores = pred.get('interval_scores', {})
            
            best_score = 0
            capped_score = 0  # âœ… ì´ˆê¸°í™” ì¶”ê°€
            valid_scores = []  # âœ… valid_scoresë„ ì™¸ë¶€ì—ì„œ ì´ˆê¸°í™”
            
            if interval_scores and isinstance(interval_scores, dict):
                # ìœ íš¨í•œ interval score ì°¾ê¸°
                for score_data in interval_scores.values():
                    if isinstance(score_data, dict) and 'score' in score_data:
                        score_value = score_data.get('score', 0)
                        if isinstance(score_value, (int, float)):
                            valid_scores.append(score_value)
                
                if valid_scores:
                    best_score = max(valid_scores)
                    # ì ìˆ˜ë¥¼ 3ì ìœ¼ë¡œ ì œí•œ (ê° ì˜ˆì¸¡ì˜ ìµœëŒ€ ì ìˆ˜)
                    capped_score = min(best_score, 3.0)
                    total_best_score += capped_score
            
            debug_info['individual_scores'].append({
                'date': pred_date,
                'original_best_score': best_score,
                'actual_score_used': capped_score if valid_scores else 0,
                'max_score_per_prediction': 3,
                'has_valid_scores': len(valid_scores) > 0
            })
        
        # ì „ì²´ ê³„ì‚° - 3ì ì´ ë§Œì 
        max_possible_total_score = prediction_count * 3
        reliability_percentage = (total_best_score / max_possible_total_score) * 100 if max_possible_total_score > 0 else 0.0
        
        debug_info['total_best_score'] = total_best_score
        debug_info['max_possible_total_score'] = max_possible_total_score
        debug_info['reliability_percentage'] = reliability_percentage
        
        logger.info(f"ğŸ¯ ì˜¬ë°”ë¥¸ ëˆ„ì  êµ¬ë§¤ ì‹ ë¢°ë„ ê³„ì‚°:")
        logger.info(f"  - ì˜ˆì¸¡ íšŸìˆ˜: {prediction_count}íšŒ")
        
        # ğŸ” ê°œë³„ ì ìˆ˜ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        for score_info in debug_info['individual_scores']:
            original = score_info.get('original_best_score', 0)
            actual = score_info.get('actual_score_used', 0)
            logger.info(f"ğŸ“Š ë‚ ì§œ {score_info['date']}: ì›ë³¸ì ìˆ˜={original:.1f}, ì ìš©ì ìˆ˜={actual:.1f}, ìœ íš¨ì ìˆ˜ìˆìŒ={score_info['has_valid_scores']}")
        
        logger.info(f"  - ì´ íšë“ ì ìˆ˜: {total_best_score:.1f}ì ")
        logger.info(f"  - ìµœëŒ€ ê°€ëŠ¥ ì ìˆ˜: {max_possible_total_score}ì  ({prediction_count} Ã— 3)")
        logger.info(f"  - êµ¬ë§¤ ì‹ ë¢°ë„: {reliability_percentage:.1f}%")
        
        # âœ… ì¶”ê°€ ê²€ì¦ ë¡œê¹…
        if reliability_percentage == 100.0:
            logger.warning("âš ï¸ [RELIABILITY] êµ¬ë§¤ ì‹ ë¢°ë„ê°€ 100%ì…ë‹ˆë‹¤. ê³„ì‚° ê²€ì¦:")
            logger.warning(f"   - total_best_score: {total_best_score}")
            logger.warning(f"   - max_possible_total_score: {max_possible_total_score}")
            logger.warning(f"   - prediction_count: {prediction_count}")
            for i, score_info in enumerate(debug_info['individual_scores']):
                logger.warning(f"   - ì˜ˆì¸¡ {i+1}: {score_info}")
        elif reliability_percentage == 0.0:
            logger.warning("âš ï¸ [RELIABILITY] êµ¬ë§¤ ì‹ ë¢°ë„ê°€ 0%ì…ë‹ˆë‹¤. ê³„ì‚° ê²€ì¦:")
            logger.warning(f"   - total_best_score: {total_best_score}")
            logger.warning(f"   - max_possible_total_score: {max_possible_total_score}")
            logger.warning(f"   - prediction_count: {prediction_count}")
        
        return reliability_percentage, debug_info
            
    except Exception as e:
        logger.error(f"Error calculating accumulated purchase reliability: {str(e)}")
        return 0.0, {'error': str(e)}

def calculate_actual_business_days(predictions):
    """
    ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ì‹¤ì œ ì˜ì—…ì¼ ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    """
    if not predictions:
        return 0
    
    try:
        actual_days = len([p for p in predictions 
                          if p.get('Date') and not p.get('is_synthetic', False)])
        return actual_days
    except Exception as e:
        logger.error(f"Error calculating actual business days: {str(e)}")
        return 0

def get_previous_semimonthly_period(semimonthly_period):
    """
    ì£¼ì–´ì§„ ë°˜ì›” ê¸°ê°„ì˜ ì´ì „ ë°˜ì›” ê¸°ê°„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Parameters:
    -----------
    semimonthly_period : str
        "YYYY-MM-SM1" ë˜ëŠ” "YYYY-MM-SM2" í˜•ì‹ì˜ ë°˜ì›” ê¸°ê°„
    
    Returns:
    --------
    str
        ì´ì „ ë°˜ì›” ê¸°ê°„
    """
    parts = semimonthly_period.split('-')
    year = int(parts[0])
    month = int(parts[1])
    half = parts[2]
    
    if half == "SM1":
        # ìƒë°˜ì›”ì¸ ê²½ìš° ì´ì „ ì›”ì˜ í•˜ë°˜ì›”ë¡œ
        if month == 1:
            return f"{year-1}-12-SM2"
        else:
            return f"{year}-{month-1:02d}-SM2"
    else:
        # í•˜ë°˜ì›”ì¸ ê²½ìš° ê°™ì€ ì›”ì˜ ìƒë°˜ì›”ë¡œ
        return f"{year}-{month:02d}-SM1"