import pandas as pd
import numpy as np
import time
import logging
from threading import Thread
from datetime import datetime, timedelta
import traceback
import logging
import json
import os

from app.data.loader import load_data
from app.data.cache_manager import check_existing_prediction, load_accumulated_predictions_from_csv, rebuild_predictions_index_from_existing_files, get_file_cache_dirs
from app.prediction.predictor import generate_predictions_with_save
from app.prediction.metrics import calculate_prediction_consistency, calculate_accumulated_purchase_reliability, calculate_actual_business_days
from app.visualization.plotter import visualize_accumulated_metrics, plot_prediction_basic, plot_moving_average_analysis
from app.visualization.attention_viz import visualize_attention_weights
from app.utils.date_utils import format_date, is_holiday
from app.utils.file_utils import cleanup_excel_processes, set_seed
from app.utils.serialization import safe_serialize_value, clean_predictions_data, clean_cached_predictions, clean_interval_scores_safe, convert_to_legacy_format
from app.core.state_manager import prediction_state
from app.core.gpu_manager import log_device_usage, check_gpu_availability
from app.models.varmax_model import VARMAXSemiMonthlyForecaster


DEFAULT_DEVICE, CUDA_AVAILABLE = check_gpu_availability()
logger = logging.getLogger(__name__)

def calculate_estimated_time_remaining(start_time, current_progress):
    """
    ì˜ˆì¸¡ ì‹œì‘ ì‹œê°„ê³¼ í˜„ì¬ ì§„í–‰ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ë‚¨ì€ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        start_time: ì˜ˆì¸¡ ì‹œì‘ ì‹œê°„ (time.time() ê°’)
        current_progress: í˜„ì¬ ì§„í–‰ë¥  (0-100)
    
    Returns:
        dict: {
            'estimated_remaining_seconds': int,
            'estimated_remaining_text': str,
            'elapsed_time_seconds': int,
            'elapsed_time_text': str
        }
    """
    if not start_time or current_progress <= 0:
        return {
            'estimated_remaining_seconds': None,
            'estimated_remaining_text': 'ê³„ì‚° ì¤‘...',
            'elapsed_time_seconds': 0,
            'elapsed_time_text': '0ì´ˆ'
        }
    
    current_time = time.time()
    elapsed_time = current_time - start_time
    
    # ì§„í–‰ë¥ ì´ 100% ì´ìƒì´ë©´ ì™„ë£Œ
    if current_progress >= 100:
        return {
            'estimated_remaining_seconds': 0,
            'estimated_remaining_text': 'ì™„ë£Œ',
            'elapsed_time_seconds': int(elapsed_time),
            'elapsed_time_text': format_time_duration(int(elapsed_time))
        }
    
    # ì§„í–‰ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    estimated_total_time = elapsed_time * (100 / current_progress)
    estimated_remaining_time = estimated_total_time - elapsed_time
    
    # ìŒìˆ˜ê°€ ë˜ì§€ ì•Šë„ë¡ ë³´ì •
    estimated_remaining_time = max(0, estimated_remaining_time)
    
    return {
        'estimated_remaining_seconds': int(estimated_remaining_time),
        'estimated_remaining_text': format_time_duration(int(estimated_remaining_time)),
        'elapsed_time_seconds': int(elapsed_time),
        'elapsed_time_text': format_time_duration(int(elapsed_time))
    }

def format_time_duration(seconds):
    """ì‹œê°„ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if seconds < 60:
        return f"{seconds}ì´ˆ"
    elif seconds < 3600:
        minutes = seconds // 60
        remaining_seconds = seconds % 60
        if remaining_seconds > 0:
            return f"{minutes}ë¶„ {remaining_seconds}ì´ˆ"
        else:
            return f"{minutes}ë¶„"
    else:
        hours = seconds // 3600
        remaining_minutes = (seconds % 3600) // 60
        if remaining_minutes > 0:
            return f"{hours}ì‹œê°„ {remaining_minutes}ë¶„"
        else:
            return f"{hours}ì‹œê°„"
        
def run_accumulated_predictions_with_save(file_path, start_date, end_date=None, save_to_csv=True, use_saved_data=True):
    """
    ì‹œì‘ ë‚ ì§œë¶€í„° ì¢…ë£Œ ë‚ ì§œê¹Œì§€ ê° ë‚ ì§œë³„ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ëˆ„ì í•©ë‹ˆë‹¤. (ìµœì í™”ë¨ - ë°ì´í„° í•œë²ˆë§Œ ë¡œë”©)
    """
    global prediction_state

    try:
        # ìƒíƒœ ì´ˆê¸°í™”
        prediction_state['is_predicting'] = True
        prediction_state['prediction_progress'] = 5
        prediction_state['prediction_start_time'] = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        prediction_state['error'] = None
        prediction_state['accumulated_predictions'] = []
        prediction_state['accumulated_metrics'] = {}
        prediction_state['prediction_dates'] = []
        prediction_state['accumulated_consistency_scores'] = {}
        prediction_state['current_file'] = file_path  # âœ… í˜„ì¬ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        prediction_state['latest_file_path'] = file_path  # ë‹¨ì¼ ì˜ˆì¸¡ê³¼ í˜¸í™˜ì„± ìœ ì§€
        
        logger.info(f"ğŸ¯ [ACCUMULATED] Running accumulated predictions from {start_date} to {end_date}")
        logger.info(f"  ğŸ“ Data file: {file_path}")
        logger.info(f"  ğŸ’¾ Save to CSV: {save_to_csv}")
        logger.info(f"  ğŸ”„ Use saved data: {use_saved_data}")

        # ì…ë ¥ ë‚ ì§œë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
        if isinstance(start_date, str):
            start_date = pd.to_datetime(start_date)
        if end_date is not None and isinstance(end_date, str):
            end_date = pd.to_datetime(end_date)

        # ğŸš€ ë°ì´í„° ë¡œë“œ (ëˆ„ì  ì˜ˆì¸¡ìš© - LSTM ëª¨ë¸, 2022ë…„ ì´ì „ ë°ì´í„° ì œê±°) - í•œ ë²ˆë§Œ ìˆ˜í–‰!
        logger.info("ğŸ“‚ [ACCUMULATED] Loading data once for all predictions...")
        df = load_data(file_path, model_type='lstm')
        prediction_state['current_data'] = df
        prediction_state['prediction_progress'] = 8
        logger.info(f"âœ… [ACCUMULATED] Data loaded successfully: {df.shape} (from {df.index.min()} to {df.index.max()})")

        # ì €ì¥ëœ ë°ì´í„° í™œìš© ì˜µì…˜ì´ ì¼œì ¸ ìˆìœ¼ë©´ ë¨¼ì € CSVì—ì„œ ë¡œë“œ ì‹œë„
        loaded_predictions = []
        if use_saved_data:
            logger.info("ğŸ” [CACHE] Attempting to load existing predictions from CSV files...")
            
            # ğŸ”§ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ íŒŒì¼ë“¤ë¡œë¶€í„° ì¬ìƒì„±
            cache_dirs = get_file_cache_dirs(file_path)
            predictions_index_file = cache_dirs['predictions'] / 'predictions_index.cs'
            
            if not predictions_index_file.exists():
                logger.warning("âš ï¸ [CACHE] predictions_index.cs not found, attempting to rebuild from existing files...")
                if rebuild_predictions_index_from_existing_files():
                    logger.info("âœ… [CACHE] Successfully rebuilt predictions index")
                else:
                    logger.warning("âš ï¸ [CACHE] Failed to rebuild predictions index")
            
            loaded_predictions = load_accumulated_predictions_from_csv(start_date, end_date, file_path=file_path)  # âœ… íŒŒì¼ ê²½ë¡œ ì¶”ê°€
            logger.info(f"ğŸ“¦ [CACHE] Successfully loaded {len(loaded_predictions)} predictions from CSV cache")
            if len(loaded_predictions) > 0:
                logger.info(f"ğŸ’¡ [CACHE] Using cached predictions will significantly speed up processing!")

        prediction_state['prediction_progress'] = 10

        # ì¢…ë£Œ ë‚ ì§œê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œ ì‚¬ìš©
        if end_date is None:
            end_date = df.index.max()

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì¶”ì¶œ í›„ ì •ë ¬
        available_dates = [date for date in df.index if start_date <= date <= end_date]
        available_dates.sort()
        
        if not available_dates:
            raise ValueError(f"ì§€ì •ëœ ê¸°ê°„ ë‚´ì— ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤: {start_date} ~ {end_date}")

        total_dates = len(available_dates)
        logger.info(f"Accumulated prediction: {total_dates} dates from {start_date} to {end_date}")

        # ëˆ„ì  ì„±ëŠ¥ ì§€í‘œ ì´ˆê¸°í™”
        accumulated_metrics = {
            'f1': 0.0,
            'accuracy': 0.0,
            'mape': 0.0,
            'weighted_score': 0.0,
            'total_predictions': 0
        }

        # ì´ë¯¸ ë¡œë“œëœ ì˜ˆì¸¡ ê²°ê³¼ë“¤ì„ ë‚ ì§œë³„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        loaded_by_date = {}
        for pred in loaded_predictions:
            loaded_by_date[pred['date']] = pred

        # âœ… ìºì‹œ í™œìš© í†µê³„ ì´ˆê¸°í™”
        cache_statistics = {
            'total_dates': 0,
            'cached_dates': 0,
            'new_predictions': 0,
            'cache_hit_rate': 0.0
        }

        all_predictions = []
        accumulated_interval_scores = {}

        # ê° ë‚ ì§œë³„ ì˜ˆì¸¡ ìˆ˜í–‰ ë˜ëŠ” ë¡œë“œ
        for i, current_date in enumerate(available_dates):
            current_date_str = format_date(current_date)
            cache_statistics['total_dates'] += 1
            
            logger.info(f"Processing date {i+1}/{total_dates}: {current_date_str}")
            
            # ì´ë¯¸ ë¡œë“œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if current_date_str in loaded_by_date:
                cache_statistics['cached_dates'] += 1  # âœ… ìºì‹œ ì‚¬ìš© ì‹œ ì¹´ìš´í„° ì¦ê°€
                logger.info(f"âš¡ [CACHE] Using cached prediction for {current_date_str} (skipping computation)")
                date_result = loaded_by_date[current_date_str]
                
                # ğŸ”§ ìºì‹œëœ metrics ì•ˆì „ì„± ì²˜ë¦¬
                metrics = date_result.get('metrics')
                if not metrics or not isinstance(metrics, dict):
                    logger.warning(f"âš ï¸ [CACHE] Invalid metrics for {current_date_str}, using defaults")
                    metrics = {'f1': 0.0, 'accuracy': 0.0, 'mape': 0.0, 'weighted_score': 0.0}
                
                # ëˆ„ì  ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
                accumulated_metrics['f1'] += metrics.get('f1', 0.0)
                accumulated_metrics['accuracy'] += metrics.get('accuracy', 0.0)
                accumulated_metrics['mape'] += metrics.get('mape', 0.0)
                accumulated_metrics['weighted_score'] += metrics.get('weighted_score', 0.0)
                accumulated_metrics['total_predictions'] += 1
                
            else:
                # ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
                cache_statistics['new_predictions'] += 1
                logger.info(f"ğŸš€ [COMPUTE] Running new prediction for {current_date_str} (not in cache)")
                try:
                    # âœ… ëˆ„ì  ì˜ˆì¸¡ì—ì„œë„ ëª¨ë“  ìƒˆ ì˜ˆì¸¡ì„ ì €ì¥í•˜ë„ë¡ ë³´ì¥
                    results = generate_predictions_with_save(df, current_date, save_to_csv=True, file_path=file_path)
                    
                    # ì˜ˆì¸¡ ë°ì´í„° íƒ€ì… ì•ˆì „ í™•ì¸
                    predictions = results.get('predictions_flat', results.get('predictions', []))
                    
                    # ì˜ˆì¸¡ ë°ì´í„°ê°€ ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(predictions, dict):
                        if 'future' in predictions:
                            predictions = predictions['future']
                        elif 'predictions' in predictions:
                            predictions = predictions['predictions']
                    
                    if not predictions or not isinstance(predictions, list):
                        logger.warning(f"No valid predictions found for {current_date_str}: {type(predictions)}")
                        continue
                        
                    # ì‹¤ì œ ì˜ˆì¸¡í•œ ì˜ì—…ì¼ ìˆ˜ ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹)
                    actual_business_days = 0
                    try:
                        for p in predictions:
                            # pê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                            if isinstance(p, dict):
                                date_key = p.get('Date') or p.get('date')
                                is_synthetic = p.get('is_synthetic', False)
                                if date_key and not is_synthetic:
                                    actual_business_days += 1
                            else:
                                logger.warning(f"Prediction item is not dict for {current_date_str}: {type(p)}")
                    except Exception as calc_error:
                        logger.error(f"Error calculating business days: {str(calc_error)}")
                        actual_business_days = len(predictions)  # ê¸°ë³¸ê°’
                    
                    metrics = results.get('metrics', {})
                    if not metrics:
                        # ë©”íŠ¸ë¦­ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
                        metrics = {'f1': 0.0, 'accuracy': 0.0, 'mape': 0.0, 'weighted_score': 0.0}
                    
                    # ëˆ„ì  ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
                    accumulated_metrics['f1'] += metrics.get('f1', 0.0)
                    accumulated_metrics['accuracy'] += metrics.get('accuracy', 0.0)
                    accumulated_metrics['mape'] += metrics.get('mape', 0.0)
                    accumulated_metrics['weighted_score'] += metrics.get('weighted_score', 0.0)
                    accumulated_metrics['total_predictions'] += 1

                    # ì•ˆì „í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±
                    safe_predictions = predictions if isinstance(predictions, list) else []
                    safe_interval_scores = results.get('interval_scores', {})
                    if not isinstance(safe_interval_scores, dict):
                        safe_interval_scores = {}
                    
                    date_result = {
                        'date': current_date_str,
                        'predictions': safe_predictions,
                        'metrics': metrics,
                        'interval_scores': safe_interval_scores,
                        'actual_business_days': actual_business_days,
                        'next_semimonthly_period': results.get('next_semimonthly_period'),
                        'original_interval_scores': safe_interval_scores,
                        'ma_results': results.get('ma_results', {}),  # ğŸ”‘ ì´ë™í‰ê·  ë°ì´í„° ì¶”ê°€
                        'attention_data': results.get('attention_data', {})  # ğŸ”‘ Attention ë°ì´í„° ì¶”ê°€
                    }
                    
                except Exception as e:
                    logger.error(f"Error in prediction for date {current_date}: {str(e)}")
                    logger.error(traceback.format_exc())
                    continue

            # êµ¬ê°„ ì ìˆ˜ ëˆ„ì  ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
            interval_scores = date_result.get('interval_scores', {})
            if isinstance(interval_scores, dict):
                for interval in interval_scores.values():
                    if not interval or not isinstance(interval, dict) or 'days' not in interval or interval['days'] is None:
                        continue
                    interval_key = f"{format_date(interval['start_date'])}-{format_date(interval['end_date'])}"
                    if interval_key in accumulated_interval_scores:
                        accumulated_interval_scores[interval_key]['score'] += interval['score']
                        accumulated_interval_scores[interval_key]['count'] += 1
                        accumulated_interval_scores[interval_key]['avg_price'] = (
                            (accumulated_interval_scores[interval_key]['avg_price'] *
                             (accumulated_interval_scores[interval_key]['count'] - 1) +
                             interval['avg_price']) / accumulated_interval_scores[interval_key]['count']
                        )
                    else:
                        accumulated_interval_scores[interval_key] = interval.copy()
                        accumulated_interval_scores[interval_key]['count'] = 1

            all_predictions.append(date_result)
            prediction_state['prediction_progress'] = 10 + int(90 * (i + 1) / total_dates)

        # í‰ê·  ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        if accumulated_metrics['total_predictions'] > 0:
            count = accumulated_metrics['total_predictions']
            accumulated_metrics['f1'] /= count
            accumulated_metrics['accuracy'] /= count
            accumulated_metrics['mape'] /= count
            accumulated_metrics['weighted_score'] /= count
            
            # ğŸ”§ NaN ê°’ ì²˜ë¦¬ ê°•í™”
            for metric_key in ['f1', 'accuracy', 'mape', 'weighted_score']:
                if pd.isna(accumulated_metrics[metric_key]) or np.isnan(accumulated_metrics[metric_key]) or np.isinf(accumulated_metrics[metric_key]):
                    logger.warning(f"âš ï¸ [METRICS] NaN/Inf detected in {metric_key}, setting to 0.0")
                    accumulated_metrics[metric_key] = 0.0

        # ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°
        logger.info("Calculating prediction consistency scores...")
        unique_periods = set()
        for pred in all_predictions:
            if 'next_semimonthly_period' in pred and pred['next_semimonthly_period']:
                unique_periods.add(pred['next_semimonthly_period'])
        
        accumulated_consistency_scores = {}
        for period in unique_periods:
            try:
                consistency_data = calculate_prediction_consistency(all_predictions, period)
                # ğŸ”§ NaN ê°’ ì²˜ë¦¬ ê°•í™”
                if consistency_data and 'consistency_score' in consistency_data:
                    consistency_score = consistency_data['consistency_score']
                    if pd.isna(consistency_score) or np.isnan(consistency_score) or np.isinf(consistency_score):
                        logger.warning(f"âš ï¸ [CONSISTENCY] NaN/Inf detected for period {period}, setting to 0.0")
                        consistency_data['consistency_score'] = 0.0
                accumulated_consistency_scores[period] = consistency_data
                logger.info(f"Consistency score for {period}: {consistency_data.get('consistency_score', 'N/A')}")
            except Exception as e:
                logger.error(f"Error calculating consistency for period {period}: {str(e)}")

        # accumulated_interval_scores ì²˜ë¦¬
        accumulated_scores_list = [
            v for v in accumulated_interval_scores.values()
            if v is not None and isinstance(v, dict) and 'days' in v and v['days'] is not None
        ]
        accumulated_scores_list.sort(key=lambda x: x['score'], reverse=True)

        accumulated_purchase_reliability, debug_info = calculate_accumulated_purchase_reliability(all_predictions)
        
        # âœ… ìºì‹œ í™œìš©ë¥  ê³„ì‚°
        cache_statistics['cache_hit_rate'] = (cache_statistics['cached_dates'] / cache_statistics['total_dates'] * 100) if cache_statistics['total_dates'] > 0 else 0.0
        # ğŸ”§ NaN ê°’ ì²˜ë¦¬ ê°•í™”
        if pd.isna(cache_statistics['cache_hit_rate']) or np.isnan(cache_statistics['cache_hit_rate']) or np.isinf(cache_statistics['cache_hit_rate']):
            logger.warning(f"âš ï¸ [CACHE] NaN/Inf detected in cache_hit_rate, setting to 0.0")
            cache_statistics['cache_hit_rate'] = 0.0
        logger.info(f"ğŸ¯ [CACHE] Final statistics: {cache_statistics['cached_dates']}/{cache_statistics['total_dates']} cached ({cache_statistics['cache_hit_rate']:.1f}%), {cache_statistics['new_predictions']} new predictions computed")
        
        # ê²°ê³¼ ì €ì¥
        prediction_state['accumulated_predictions'] = all_predictions
        prediction_state['accumulated_metrics'] = accumulated_metrics
        prediction_state['prediction_dates'] = [p['date'] for p in all_predictions]
        prediction_state['accumulated_interval_scores'] = accumulated_scores_list
        prediction_state['accumulated_consistency_scores'] = accumulated_consistency_scores
        prediction_state['accumulated_purchase_reliability'] = accumulated_purchase_reliability
        prediction_state['accumulated_purchase_debug'] = debug_info
        prediction_state['cache_statistics'] = cache_statistics  # âœ… ìºì‹œ í†µê³„ ì¶”ê°€

        if all_predictions:
            latest = all_predictions[-1]
            prediction_state['latest_predictions'] = latest['predictions']
            prediction_state['current_date'] = latest['date']

        prediction_state['is_predicting'] = False
        prediction_state['prediction_progress'] = 100
        logger.info(f"Accumulated prediction completed for {len(all_predictions)} dates")
        
        # ğŸ”§ Excel í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
        cleanup_excel_processes()
        
    except Exception as e:
        logger.error(f"Error in accumulated prediction: {str(e)}")
        logger.error(traceback.format_exc())
        prediction_state['error'] = str(e)
        prediction_state['is_predicting'] = False
        prediction_state['prediction_progress'] = 0
        prediction_state['accumulated_consistency_scores'] = {}
        
        # ğŸ”§ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ Excel í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
        cleanup_excel_processes()

def background_accumulated_prediction(file_path, start_date, end_date=None):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëˆ„ì  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    thread = Thread(target=run_accumulated_predictions_with_save, args=(file_path, start_date, end_date))
    thread.daemon = True
    thread.start()
    return thread

def background_prediction_simple_compatible(file_path, current_date, save_to_csv=True, use_cache=True):
    """í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì˜ˆì¸¡ í•¨ìˆ˜ - ìºì‹œ ìš°ì„  ì‚¬ìš©, JSON ì•ˆì „ì„± ë³´ì¥"""
    global prediction_state
    
    try:
        # ì¼ê´€ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ê³ ì •
        set_seed()
        prediction_state['is_predicting'] = True
        prediction_state['prediction_progress'] = 10
        prediction_state['prediction_start_time'] = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        prediction_state['error'] = None
        prediction_state['latest_file_path'] = file_path  # íŒŒì¼ ê²½ë¡œ ì €ì¥
        prediction_state['current_file'] = file_path  # ìºì‹œ ì—°ë™ìš© íŒŒì¼ ê²½ë¡œ
        
        logger.info(f"ğŸ¯ Starting compatible prediction for {current_date}")
        logger.info(f"  ğŸ”„ Cache enabled: {use_cache}")
        
        # ë°ì´í„° ë¡œë“œ (ë‹¨ì¼ ë‚ ì§œ ì˜ˆì¸¡ìš© - LSTM ëª¨ë¸, 2022ë…„ ì´ì „ ë°ì´í„° ì œê±°)
        df = load_data(file_path, model_type='lstm')
        prediction_state['current_data'] = df
        prediction_state['prediction_progress'] = 20
        
        # í˜„ì¬ ë‚ ì§œ ì²˜ë¦¬ ë° ì˜ì—…ì¼ ì¡°ì •
        if current_date is None:
            current_date = df.index.max()
        else:
            current_date = pd.to_datetime(current_date)
        
        # ğŸ¯ íœ´ì¼ì´ë©´ ë‹¤ìŒ ì˜ì—…ì¼ë¡œ ì¡°ì •
        original_date = current_date
        adjusted_date = current_date
        
        # ì£¼ë§ì´ë‚˜ íœ´ì¼ì´ë©´ ë‹¤ìŒ ì˜ì—…ì¼ë¡œ ì´ë™
        while adjusted_date.weekday() >= 5 or is_holiday(adjusted_date):
            adjusted_date += pd.Timedelta(days=1)
        
        if adjusted_date != original_date:
            logger.info(f"ğŸ“… Date adjusted for business day: {original_date.strftime('%Y-%m-%d')} -> {adjusted_date.strftime('%Y-%m-%d')}")
            logger.info(f"  ğŸ“‹ Reason: {'Weekend' if original_date.weekday() >= 5 else 'Holiday'}")
        
        current_date = adjusted_date
        
        # ìºì‹œ í™•ì¸ - í™•ì¥ ë°ì´í„° ìŠ¤ë§ˆíŠ¸ í™œìš©
        if use_cache:
            logger.info("ğŸ” Checking for existing prediction cache...")
            prediction_state['prediction_progress'] = 30
            
            try:
                from app.data.cache_manager import check_existing_prediction, find_compatible_cache_file, load_existing_predictions_for_extension
                # 1. ë¨¼ì € íŠ¹ì • ë‚ ì§œì˜ ì •í™•í•œ ìºì‹œ í™•ì¸
                cached_result = check_existing_prediction(current_date, file_path)
                logger.info(f"  ğŸ“‹ Direct cache check result: {cached_result is not None}")
                
                # 2. ì§ì ‘ ìºì‹œê°€ ì—†ìœ¼ë©´ í™•ì¥ ë°ì´í„° ìºì‹œ í™œìš© ê²€í† 
                if not cached_result or not cached_result.get('success'):
                    logger.info("ğŸ”„ Direct cache not found, checking for extension cache compatibility...")
                    
                    # í˜„ì¬ íŒŒì¼ì´ í™•ì¥ëœ ë°ì´í„°ì¸ì§€ í™•ì¸
                    logger.info(f"ğŸ” [EXTENSION_CHECK] Checking for compatible cache files...")
                    compatibility_info = find_compatible_cache_file(file_path)
                    
                    logger.info(f"ğŸ“Š [EXTENSION_CHECK] Compatibility check result:")
                    logger.info(f"    Found: {compatibility_info.get('found')}")
                    logger.info(f"    Cache type: {compatibility_info.get('cache_type')}")
                    logger.info(f"    Cache files: {len(compatibility_info.get('cache_files', []))}")
                    
                    if (compatibility_info.get('found') and 
                        compatibility_info.get('cache_type') in ['extension', 'hash_based', 'near_complete']):
                        
                        logger.info("ğŸ“ˆ Extension data detected! Attempting smart cache utilization...")
                        
                        # ê¸°ì¡´ ìºì‹œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜ˆì¸¡ë“¤ ë¡œë“œ
                        existing_predictions = load_existing_predictions_for_extension(
                            file_path, current_date, compatibility_info
                        )
                        
                        if existing_predictions:
                            logger.info(f"âœ… Found {len(existing_predictions)} existing predictions to reuse!")
                            
                            # ğŸ”§ ê°œì„ ëœ ë¡œì§: ë¶€ë¶„ì  ìºì‹œ ì¬í™œìš© + ìƒˆë¡œìš´ ë‚ ì§œ ì¶”ê°€ ì˜ˆì¸¡
                            existing_dates = [pd.to_datetime(p['Date']) for p in existing_predictions]
                            existing_date_range = (min(existing_dates), max(existing_dates))
                            
                            logger.info(f"ğŸ“… Existing prediction range: {existing_date_range[0].strftime('%Y-%m-%d')} ~ {existing_date_range[1].strftime('%Y-%m-%d')}")
                            logger.info(f"ğŸ¯ Requested date: {current_date.strftime('%Y-%m-%d')}")
                            
                                                                                     # í˜„ì¬ ë‚ ì§œê°€ ê¸°ì¡´ ì˜ˆì¸¡ì— ì •í™•íˆ ìˆëŠ”ì§€ í™•ì¸
                            if current_date in existing_dates:
                                # Case 1: ì •í™•í•œ ë‚ ì§œ ë§¤ì¹˜ - ì „ì²´ ìºì‹œ ì¬í™œìš©
                                logger.info("ğŸ¯ Current date found in existing predictions - using full cache")
                                cached_result = {
                                    'success': True,
                                    'predictions': existing_predictions,
                                    'metadata': {
                                        'cache_source': 'extension_cache_full',
                                        'reused_predictions': len(existing_predictions),
                                        'target_date': current_date.strftime('%Y-%m-%d'),
                                        'extension_info': compatibility_info
                                    },
                                    'attention_data': None
                                }
                            else:
                                # Case 2: ì •í™•í•œ ë‚ ì§œ ì—†ìŒ - ë¶€ë¶„ ì¬í™œìš© + ìƒˆ ì˜ˆì¸¡ í•„ìš”
                                logger.info("ğŸ”„ Current date not in existing predictions - attempting smart hybrid approach")
                                
                                # ê¸°ì¡´ ì˜ˆì¸¡ ì¤‘ ìœ íš¨í•œ ë¶€ë¶„ë§Œ ì¬í™œìš©
                                useful_predictions = [p for p in existing_predictions 
                                                    if pd.to_datetime(p['Date']) <= existing_date_range[1]]
                                
                                if useful_predictions:
                                    logger.info(f"ğŸ“Š Will reuse {len(useful_predictions)} existing predictions")
                                    logger.info(f"ğŸ“… Need new predictions from {existing_date_range[1].strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')}")
                                    
                                    # ë¶€ë¶„ ìºì‹œ í™œìš©ì„ ìœ„í•œ íŠ¹ë³„ í”Œë˜ê·¸ ì„¤ì •
                                    cached_result = {
                                        'success': 'partial',  # ë¶€ë¶„ ì„±ê³µ í‘œì‹œ
                                        'predictions': useful_predictions,
                                        'metadata': {
                                            'cache_source': 'extension_cache_partial',
                                            'reused_predictions': len(useful_predictions),
                                            'target_date': current_date.strftime('%Y-%m-%d'),
                                            'need_additional_prediction': True,
                                            'additional_start_date': existing_date_range[1].strftime('%Y-%m-%d'),
                                            'extension_info': compatibility_info
                                        },
                                        'attention_data': None
                                    }
                                    logger.info("ğŸš€ Using partial extension cache - will supplement with new predictions")
                
                if cached_result:
                    logger.info(f"  ğŸ“‹ Final cache success status: {cached_result.get('success', False)}")
                else:
                    logger.info("  âŒ No cache result available")
                    
            except Exception as cache_check_error:
                logger.error(f"  âŒ Cache check failed with error: {str(cache_check_error)}")
                logger.error(f"  ğŸ“ Error traceback: {traceback.format_exc()}")
                cached_result = None
        else:
            logger.info("ğŸ†• Cache disabled - running new prediction...")
            cached_result = None
            
        # ğŸ”§ ê°œì„ ëœ ìºì‹œ ì²˜ë¦¬: ì™„ì „ ìºì‹œì™€ ë¶€ë¶„ ìºì‹œ ëª¨ë‘ ì²˜ë¦¬
        if cached_result and (cached_result.get('success') == True or cached_result.get('success') == 'partial'):
            
            if cached_result.get('success') == 'partial':
                logger.info("ğŸ”„ Found partial cache! Will reuse existing predictions and add new ones...")
                prediction_state['prediction_progress'] = 40
                
                # ë¶€ë¶„ ìºì‹œ í™œìš© ë¡œì§
                try:
                    # ê¸°ì¡´ ì˜ˆì¸¡ ë°ì´í„° ì •ë¦¬
                    existing_predictions = cached_result['predictions']
                    metadata = cached_result['metadata']
                    
                    logger.info(f"ğŸ“Š Reusing {len(existing_predictions)} existing predictions")
                    
                    # ìƒˆë¡œìš´ ì˜ˆì¸¡ì´ í•„ìš”í•œ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
                    additional_start_date = pd.to_datetime(metadata['additional_start_date']) + pd.Timedelta(days=1)
                    
                    logger.info(f"ğŸš€ Generating new predictions from {additional_start_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')}")
                                        # ìƒˆë¡œìš´ ë‚ ì§œ ë²”ìœ„ì— ëŒ€í•´ì„œë§Œ ì˜ˆì¸¡ ìˆ˜í–‰
                    prediction_state['prediction_progress'] = 50
                    
                    # ë¶€ë¶„ ì˜ˆì¸¡ì„ ìœ„í•´ í˜„ì¬ ë‚ ì§œê°€ ìƒˆë¡œìš´ ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
                    days_gap = (current_date - additional_start_date).days
                    if days_gap > 0 and days_gap <= 23:  # ì˜ˆì¸¡ ìœˆë„ìš° ë‚´ì— ìˆìŒ
                        logger.info(f"ğŸ“… Performing partial prediction for {days_gap} days gap")
                        new_results = generate_predictions_with_save(
                            df, current_date, 
                            save_to_csv=save_to_csv, 
                            file_path=file_path
                        )
                        
                        # ìƒˆ ì˜ˆì¸¡ì—ì„œ ê¸°ì¡´ ë‚ ì§œì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì œê±°
                        if new_results and new_results.get('predictions'):
                            new_predictions_raw = new_results['predictions']
                            if isinstance(new_predictions_raw, list):
                                new_predictions = new_predictions_raw
                            else:
                                new_predictions = new_results.get('predictions_flat', [])
                            
                            # ì¤‘ë³µ ì œê±°: ê¸°ì¡´ ë‚ ì§œ ì´í›„ì˜ ì˜ˆì¸¡ë§Œ ì‚¬ìš©
                            existing_latest_date = max(existing_dates)
                            filtered_new_predictions = []
                            for pred in new_predictions:
                                pred_date = pd.to_datetime(pred.get('date') or pred.get('Date'))
                                if pred_date > existing_latest_date:
                                    filtered_new_predictions.append(pred)
                            
                            logger.info(f"ğŸ“Š Filtered {len(filtered_new_predictions)} new predictions (removed {len(new_predictions) - len(filtered_new_predictions)} duplicates)")
                            new_results['predictions'] = filtered_new_predictions
                            
                    else:
                        logger.warning(f"âš ï¸ Date gap too large ({days_gap} days), performing full prediction")
                        new_results = generate_predictions_with_save(
                            df, current_date, 
                            save_to_csv=save_to_csv, 
                            file_path=file_path
                        )
                    
                    prediction_state['prediction_progress'] = 70
                                        # ê¸°ì¡´ ì˜ˆì¸¡ê³¼ ìƒˆ ì˜ˆì¸¡ ê²°í•©
                    if new_results and new_results.get('predictions'):
                        new_predictions = new_results['predictions']
                        if isinstance(new_predictions, list):
                            combined_predictions = existing_predictions + new_predictions
                        else:
                            combined_predictions = existing_predictions + new_results.get('predictions_flat', [])
                        
                        # ë‚ ì§œìˆœ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
                        combined_predictions.sort(key=lambda x: pd.to_datetime(x.get('date') or x.get('Date')))
                        
                        # ìµœì¢… ì¤‘ë³µ í™•ì¸ (ì•ˆì „ì¥ì¹˜)
                        seen_dates = set()
                        unique_predictions = []
                        for pred in combined_predictions:
                            pred_date = pd.to_datetime(pred.get('date') or pred.get('Date')).strftime('%Y-%m-%d')
                            if pred_date not in seen_dates:
                                seen_dates.add(pred_date)
                                unique_predictions.append(pred)
                        
                        combined_predictions = unique_predictions
                        logger.info(f"âœ… Combined {len(existing_predictions)} existing + {len(new_predictions)} new = {len(combined_predictions)} total predictions (after deduplication)")
                        
                        # í˜¸í™˜ì„± ìœ ì§€ëœ í˜•íƒœë¡œ ë³€í™˜
                        compatible_predictions = convert_to_legacy_format(combined_predictions)
                        
                        # ê²°í•©ëœ ê²°ê³¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
                        prediction_state['latest_predictions'] = compatible_predictions
                        prediction_state['latest_attention_data'] = new_results.get('attention_data')
                        prediction_state['current_date'] = safe_serialize_value(new_results.get('current_date'))
                        prediction_state['selected_features'] = new_results.get('selected_features', [])
                        prediction_state['semimonthly_period'] = safe_serialize_value(new_results.get('semimonthly_period'))
                        prediction_state['next_semimonthly_period'] = safe_serialize_value(new_results.get('next_semimonthly_period'))
                        prediction_state['latest_interval_scores'] = new_results.get('interval_scores', {})
                        prediction_state['latest_metrics'] = new_results.get('metrics')
                        prediction_state['latest_plots'] = new_results.get('plots', {})
                        prediction_state['latest_ma_results'] = new_results.get('ma_results', {})
                        
                        # feature_importance ì„¤ì •
                        if new_results.get('attention_data') and 'feature_importance' in new_results['attention_data']:
                            prediction_state['feature_importance'] = new_results['attention_data']['feature_importance']
                        else:
                            prediction_state['feature_importance'] = None
                        
                        prediction_state['prediction_progress'] = 100
                        prediction_state['is_predicting'] = False
                        logger.info("âœ… Hybrid prediction (partial cache + new predictions) completed successfully!")
                        return
                    else:
                        logger.warning("âš ï¸ New prediction failed, falling back to full prediction...")
                        
                except Exception as partial_error:
                    logger.error(f"âŒ Partial cache processing failed: {str(partial_error)}")
                    logger.info("ğŸ”„ Falling back to full prediction...")
                    
            else:
                logger.info("ğŸ‰ Found existing prediction! Loading from cache...")
                prediction_state['prediction_progress'] = 50
            
            try:
                    from app.prediction.metrics import calculate_moving_averages_with_history
                    # ìºì‹œëœ ë°ì´í„° ë¡œë“œ ë° ì •ë¦¬
                    predictions = cached_result['predictions']
                    metadata = cached_result['metadata']
                    attention_data = cached_result.get('attention_data')
                    
                    # ë°ì´í„° ì •ë¦¬ (JSON ì•ˆì „ì„± ë³´ì¥)
                    cleaned_predictions = clean_cached_predictions(predictions)
                    
                    # í˜¸í™˜ì„± ìœ ì§€ëœ í˜•íƒœë¡œ ë³€í™˜
                    compatible_predictions = convert_to_legacy_format(cleaned_predictions)
                    
                    # JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸
                    try:
                        test_json = json.dumps(compatible_predictions[:1] if compatible_predictions else [])
                        logger.info("âœ… JSON serialization test passed for cached data")
                    except Exception as json_error:
                        logger.error(f"âŒ JSON serialization failed for cached data: {str(json_error)}")
                        raise Exception("Cached data serialization failed")
                    
                    # êµ¬ê°„ ì ìˆ˜ ì²˜ë¦¬ (JSON ì•ˆì „)
                    interval_scores = metadata.get('interval_scores', {})
                    cleaned_interval_scores = {}
                    for key, value in interval_scores.items():
                        if isinstance(value, dict):
                            cleaned_score = {}
                            for k, v in value.items():
                                cleaned_score[k] = safe_serialize_value(v)
                            cleaned_interval_scores[key] = cleaned_score
                        else:
                            cleaned_interval_scores[key] = safe_serialize_value(value)
                    
                    # ì´ë™í‰ê·  ì¬ê³„ì‚°
                    prediction_state['prediction_progress'] = 60
                    logger.info("Recalculating moving averages from cached data...")
                    historical_data = df[df.index <= current_date].copy()
                    ma_results = calculate_moving_averages_with_history(
                        cleaned_predictions, historical_data, target_col='MOPJ'
                    )
                    
                    # ì‹œê°í™” ì¬ìƒì„±
                    prediction_state['prediction_progress'] = 70
                    logger.info("Regenerating visualizations from cached data...")
                    plots = regenerate_visualizations_from_cache(
                        cleaned_predictions, df, current_date, metadata
                    )
                    
                    # ë©”íŠ¸ë¦­ ì •ë¦¬
                    metrics = metadata.get('metrics')
                    cleaned_metrics = {}
                    if metrics:
                        for key, value in metrics.items():
                            cleaned_metrics[key] = safe_serialize_value(value)
                    
                    # ì–´í…ì…˜ ë°ì´í„° ì •ë¦¬
                    cleaned_attention = None
                    logger.info(f"ğŸ“Š [CACHE_ATTENTION] Processing attention data: available={bool(attention_data)}")
                    if attention_data:
                        logger.info(f"ğŸ“Š [CACHE_ATTENTION] Original keys: {list(attention_data.keys())}")
                        
                        cleaned_attention = {}
                        for key, value in attention_data.items():
                            if key == 'image' and value:
                                cleaned_attention[key] = value  # base64 ì´ë¯¸ì§€ëŠ” ê·¸ëŒ€ë¡œ
                                logger.info(f"ğŸ“Š [CACHE_ATTENTION] Image preserved (length: {len(value)})")
                            elif isinstance(value, dict):
                                cleaned_attention[key] = {}
                                for k, v in value.items():
                                    cleaned_attention[key][k] = safe_serialize_value(v)
                                logger.info(f"ğŸ“Š [CACHE_ATTENTION] Dict '{key}' processed: {len(cleaned_attention[key])} items")
                            else:
                                cleaned_attention[key] = safe_serialize_value(value)
                                logger.info(f"ğŸ“Š [CACHE_ATTENTION] Value '{key}' processed: {type(value)}")
                        
                        logger.info(f"ğŸ“Š [CACHE_ATTENTION] Final cleaned keys: {list(cleaned_attention.keys())}")
                    else:
                        logger.warning(f"ğŸ“Š [CACHE_ATTENTION] No attention data in cache result")
                    
                    # ìƒíƒœ ì„¤ì •
                    prediction_state['latest_predictions'] = compatible_predictions
                    prediction_state['latest_attention_data'] = cleaned_attention
                    prediction_state['current_date'] = safe_serialize_value(metadata.get('prediction_start_date'))
                    prediction_state['selected_features'] = metadata.get('selected_features', [])
                    prediction_state['semimonthly_period'] = safe_serialize_value(metadata.get('semimonthly_period'))
                    prediction_state['next_semimonthly_period'] = safe_serialize_value(metadata.get('next_semimonthly_period'))
                    prediction_state['latest_interval_scores'] = cleaned_interval_scores
                    prediction_state['latest_metrics'] = cleaned_metrics
                    prediction_state['latest_plots'] = plots
                    prediction_state['latest_ma_results'] = ma_results
                    
                    # feature_importance ì„¤ì •
                    if cleaned_attention and 'feature_importance' in cleaned_attention:
                        prediction_state['feature_importance'] = cleaned_attention['feature_importance']
                    else:
                        prediction_state['feature_importance'] = None
                    
                    prediction_state['prediction_progress'] = 100
                    prediction_state['is_predicting'] = False
                    logger.info("âœ… Cache prediction completed successfully!")
                    return
                    
            except Exception as cache_error:
                logger.warning(f"âš ï¸  Cache processing failed: {str(cache_error)}")
                logger.info("ğŸ”„ Falling back to new prediction...")
        else:
            logger.info("  ğŸ“‹ No usable cache found - proceeding with new prediction")
        
        # ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
        logger.info(f"ğŸ¤– Running new prediction...")
        prediction_state['prediction_progress'] = 40
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        results = generate_predictions_with_save(df, current_date, save_to_csv=save_to_csv, file_path=file_path)
        prediction_state['prediction_progress'] = 80
        
        # ìƒˆë¡œìš´ ì˜ˆì¸¡ ê²°ê³¼ ì •ë¦¬ (JSON ì•ˆì „ì„± ë³´ì¥)
        if isinstance(results.get('predictions'), list):
            raw_predictions = results['predictions']
        else:
            raw_predictions = results.get('predictions_flat', [])
        
        # í˜¸í™˜ì„± ìœ ì§€ëœ í˜•íƒœë¡œ ë³€í™˜
        compatible_predictions = convert_to_legacy_format(raw_predictions)
        
        # JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸
        try:
            test_json = json.dumps(compatible_predictions[:1] if compatible_predictions else [])
            logger.info("âœ… JSON serialization test passed for new prediction")
        except Exception as json_error:
            logger.error(f"âŒ JSON serialization failed for new prediction: {str(json_error)}")
            # ë°ì´í„° ì¶”ê°€ ì •ë¦¬ ì‹œë„
            for pred in compatible_predictions:
                for key, value in pred.items():
                    pred[key] = safe_serialize_value(value)
        
        # ìƒíƒœ ì„¤ì •
        prediction_state['latest_predictions'] = compatible_predictions
        prediction_state['latest_attention_data'] = results.get('attention_data')
        prediction_state['current_date'] = safe_serialize_value(results.get('current_date'))
        prediction_state['selected_features'] = results.get('selected_features', [])
        prediction_state['semimonthly_period'] = safe_serialize_value(results.get('semimonthly_period'))
        prediction_state['next_semimonthly_period'] = safe_serialize_value(results.get('next_semimonthly_period'))
        prediction_state['latest_interval_scores'] = results.get('interval_scores', {})
        prediction_state['latest_metrics'] = results.get('metrics')
        prediction_state['latest_plots'] = results.get('plots', {})
        prediction_state['latest_ma_results'] = results.get('ma_results', {})
        
        # feature_importance ì„¤ì •
        if results.get('attention_data') and 'feature_importance' in results['attention_data']:
            prediction_state['feature_importance'] = results['attention_data']['feature_importance']
        else:
            prediction_state['feature_importance'] = None
        
        # ì €ì¥
        if save_to_csv:
            from app.data.cache_manager import save_prediction_simple
            logger.info("ğŸ’¾ Saving prediction to cache...")
            save_result = save_prediction_simple(results, current_date)
            if save_result['success']:
                logger.info(f"âœ… Cache saved successfully: {save_result.get('prediction_start_date')}")
            else:
                logger.warning(f"âš ï¸  Cache save failed: {save_result.get('error')}")
        
        prediction_state['prediction_progress'] = 100
        prediction_state['is_predicting'] = False
        logger.info("âœ… New prediction completed successfully")
        
    except Exception as e:
        logger.error(f"âŒ Error in compatible prediction: {str(e)}")
        logger.error(traceback.format_exc())
        prediction_state['error'] = str(e)
        prediction_state['is_predicting'] = False
        prediction_state['prediction_progress'] = 0

def generate_visualizations_realtime(predictions, df, current_date, metadata):
    """ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹œê°í™” ìƒì„± (ì €ì¥í•˜ì§€ ì•ŠìŒ)"""
    try:
        # DataFrameìœ¼ë¡œ ë³€í™˜
        sequence_df = pd.DataFrame(predictions)
        if 'Date' in sequence_df.columns:
            sequence_df['Date'] = pd.to_datetime(sequence_df['Date'])
        
        # ì‹œì‘ê°’ ê³„ì‚°
        if isinstance(current_date, str):
            current_date = pd.to_datetime(current_date)
        
        start_day_value = df.loc[current_date, 'MOPJ'] if current_date in df.index else None
        
        if start_day_value is not None:
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
            from app.prediction.metrics import compute_performance_metrics_improved
            from app.visualization.plotter import plot_prediction_basic, plot_moving_average_analysis
            from app.prediction.metrics import calculate_moving_averages_with_history
            metrics = compute_performance_metrics_improved(sequence_df, start_day_value)
            
            # ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± (ë©”ëª¨ë¦¬ì—ë§Œ)
            _, basic_plot_img = plot_prediction_basic(
                sequence_df, 
                metadata.get('prediction_start_date', current_date),
                start_day_value,
                metrics['f1'],
                metrics['accuracy'], 
                metrics['mape'],
                metrics['weighted_score'],
                save_prefix=None  # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ì‚¬ìš©
                )
                
            # ì´ë™í‰ê·  ê³„ì‚° ë° ì‹œê°í™”
            historical_data = df[df.index <= current_date].copy()
            ma_results = calculate_moving_averages_with_history(predictions, historical_data, target_col='MOPJ')
            
            _, ma_plot_img = plot_moving_average_analysis(
                ma_results,
                metadata.get('prediction_start_date', current_date),
                save_prefix=None  # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ì‚¬ìš©
            )
            
            # ìƒíƒœì— ì €ì¥
            prediction_state['latest_plots'] = {
                'basic_plot': {'file': None, 'image': basic_plot_img},
                'ma_plot': {'file': None, 'image': ma_plot_img}
            }
            prediction_state['latest_ma_results'] = ma_results
            prediction_state['latest_metrics'] = metrics
            
        else:
            logger.warning("Cannot generate visualizations: start day value not available")
            prediction_state['latest_plots'] = {
                'basic_plot': {'file': None, 'image': None},
                'ma_plot': {'file': None, 'image': None}
            }
            prediction_state['latest_ma_results'] = {}
            prediction_state['latest_metrics'] = {}
            
    except Exception as e:
        logger.error(f"Error generating realtime visualizations: {str(e)}")
        prediction_state['latest_plots'] = {
            'basic_plot': {'file': None, 'image': None},
            'ma_plot': {'file': None, 'image': None}
        }
        prediction_state['latest_ma_results'] = {}
        prediction_state['latest_metrics'] = {}

def regenerate_visualizations_from_cache(predictions, df, current_date, metadata):
    """
    ìºì‹œëœ ë°ì´í„°ë¡œë¶€í„° ì‹œê°í™”ë¥¼ ì¬ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    ğŸ”‘ current_dateë¥¼ ì „ë‹¬í•˜ì—¬ ê³¼ê±°/ë¯¸ë˜ êµ¬ë¶„ ì‹œê°í™” ìƒì„±
    """
    try:
        logger.info("ğŸ¨ Regenerating visualizations from cached data...")
        
        # DataFrameìœ¼ë¡œ ë³€í™˜ (ì•ˆì „í•œ ë°©ì‹)
        temp_df_for_plot = pd.DataFrame([
            {
                'Date': pd.to_datetime(item.get('Date') or item.get('date')),
                'Prediction': safe_serialize_value(item.get('Prediction') or item.get('prediction')),
                'Actual': safe_serialize_value(item.get('Actual') or item.get('actual'))
            } for item in predictions if item.get('Date') or item.get('date')
        ])
        
        logger.info(f"  ğŸ“Š Plot data prepared: {len(temp_df_for_plot)} predictions")
        
        # current_date ì²˜ë¦¬
        if isinstance(current_date, str):
            current_date = pd.to_datetime(current_date)
        
        # ì‹œì‘ê°’ ê³„ì‚°
        start_day_value = None
        if current_date in df.index and not pd.isna(df.loc[current_date, 'MOPJ']):
            start_day_value = df.loc[current_date, 'MOPJ']
            logger.info(f"  ğŸ“ˆ Start day value: {start_day_value:.2f}")
        else:
            logger.warning(f"  âš ï¸  Start day value not available for {current_date}")
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸° (ì•ˆì „í•œ ë°©ì‹)
        metrics = metadata.get('metrics')
        if metrics:
            f1_score = safe_serialize_value(metrics.get('f1', 0.0))
            accuracy = safe_serialize_value(metrics.get('accuracy', 0.0))
            mape = safe_serialize_value(metrics.get('mape', 0.0))
            weighted_score = safe_serialize_value(metrics.get('weighted_score', 0.0))
            logger.info(f"  ğŸ“Š Metrics loaded - F1: {f1_score:.3f}, Acc: {accuracy:.1f}%, MAPE: {mape:.1f}%")
        else:
            f1_score = accuracy = mape = weighted_score = 0.0
            logger.info("  â„¹ï¸  No metrics available - using default values")
        
        plots = {
            'basic_plot': {'file': None, 'image': None},
            'ma_plot': {'file': None, 'image': None}
        }
        
        # ì‹œê°í™” ìƒì„± (ë°ì´í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°ë§Œ)
        if start_day_value is not None and not temp_df_for_plot.empty:
            from app.prediction.metrics import calculate_moving_averages_with_history
            logger.info("  ğŸ¨ Generating basic prediction plot...")
            
            # ì˜ˆì¸¡ ì‹œì‘ì¼ ê³„ì‚°
            prediction_start_date = metadata.get('prediction_start_date')
            if isinstance(prediction_start_date, str):
                prediction_start_date = pd.to_datetime(prediction_start_date)
            elif prediction_start_date is None:
                # ë©”íƒ€ë°ì´í„°ì— ì—†ìœ¼ë©´ current_date ë‹¤ìŒ ì˜ì—…ì¼ë¡œ ê³„ì‚°
                prediction_start_date = current_date + pd.Timedelta(days=1)
                while prediction_start_date.weekday() >= 5 or is_holiday(prediction_start_date):
                    prediction_start_date += pd.Timedelta(days=1)
                logger.info(f"  ğŸ“… Calculated prediction start date: {prediction_start_date}")
            
            # âœ… í•µì‹¬ ìˆ˜ì •: current_date ì „ë‹¬í•˜ì—¬ ê³¼ê±°/ë¯¸ë˜ êµ¬ë¶„ ì‹œê°í™”
            basic_plot_file, basic_plot_img = plot_prediction_basic(
                temp_df_for_plot,
                prediction_start_date,
                start_day_value,
                f1_score,
                accuracy,
                mape,
                weighted_score,
                current_date=current_date,  # ğŸ”‘ í•µì‹¬ ìˆ˜ì •: current_date ì „ë‹¬
                save_prefix=None,  # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ì‚¬ìš©
                title_prefix="Cached Prediction Analysis"
            )
            
            if basic_plot_file:
                logger.info(f"  âœ… Basic plot generated: {basic_plot_file}")
            else:
                logger.warning("  âŒ Basic plot generation failed")
            
            # ì´ë™í‰ê·  ê³„ì‚° ë° ì‹œê°í™”
            logger.info("  ğŸ“ˆ Calculating moving averages...")
            historical_data = df[df.index <= current_date].copy()
            
            # ìºì‹œëœ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ì´ë™í‰ê·  ê³„ì‚°ìš©ìœ¼ë¡œ ë³€í™˜
            ma_input_data = []
            for pred in predictions:
                try:
                    ma_item = {
                        'Date': pd.to_datetime(pred.get('Date') or pred.get('date')),
                        'Prediction': safe_serialize_value(pred.get('Prediction') or pred.get('prediction')),
                        'Actual': safe_serialize_value(pred.get('Actual') or pred.get('actual'))
                    }
                    ma_input_data.append(ma_item)
                except Exception as e:
                    logger.warning(f"  âš ï¸  Error processing MA data item: {str(e)}")
                    continue
            
            ma_results = calculate_moving_averages_with_history(
                ma_input_data, historical_data, target_col='MOPJ'
            )
            
            if ma_results:
                logger.info(f"  ğŸ“Š MA calculated for {len(ma_results)} windows")
                
                # ì´ë™í‰ê·  ì‹œê°í™”
                ma_plot_file, ma_plot_img = plot_moving_average_analysis(
                    ma_results,
                    prediction_start_date,
                    save_prefix=None,  # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ì‚¬ìš©
                    title_prefix="Cached Moving Average Analysis"
                )
                
                if ma_plot_file:
                    logger.info(f"  âœ… MA plot generated: {ma_plot_file}")
                else:
                    logger.warning("  âŒ MA plot generation failed")
            else:
                logger.warning("  âš ï¸  Moving average calculation failed")
                ma_plot_file, ma_plot_img = None, None
            
            plots = {
                'basic_plot': {'file': basic_plot_file, 'image': basic_plot_img},
                'ma_plot': {'file': ma_plot_file, 'image': ma_plot_img}
            }
            
            logger.info("  âœ… Visualizations regenerated from cache successfully")
        else:
            if start_day_value is None:
                logger.warning("  âŒ Cannot regenerate visualizations: start day value not available")
            if temp_df_for_plot.empty:
                logger.warning("  âŒ Cannot regenerate visualizations: no prediction data")
        
        return plots
        
    except Exception as e:
        logger.error(f"âŒ Error regenerating visualizations from cache: {str(e)}")
        logger.error(traceback.format_exc())
        return {
            'basic_plot': {'file': None, 'image': None},
            'ma_plot': {'file': None, 'image': None}
        }
    
def generate_accumulated_report():
    from app.prediction.metrics import decide_purchase_interval
    """ëˆ„ì  ì˜ˆì¸¡ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
    global prediction_state
    
    if not prediction_state['accumulated_predictions']:
        return None
    
    try:
        metrics = prediction_state['accumulated_metrics']
        all_preds = prediction_state['accumulated_predictions']
        
        # ë³´ê³ ì„œ íŒŒì¼ ì´ë¦„ ìƒì„± - íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        start_date = all_preds[0]['date']
        end_date = all_preds[-1]['date']
        try:
            cache_dirs = get_file_cache_dirs()
            report_dir = cache_dirs['predictions']
            report_filename = os.path.join(report_dir, f"accumulated_report_{start_date}_to_{end_date}.txt")
        except Exception as e:
            logger.warning(f"Could not get cache directories for accumulated report: {str(e)}")
            report_filename = f"accumulated_report_{start_date}_to_{end_date}.txt"
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(f"===== Accumulated Prediction Report =====\n")
            f.write(f"Period: {start_date} to {end_date}\n")
            f.write(f"Total Predictions: {metrics['total_predictions']}\n\n")
            
            # ëˆ„ì  ì„±ëŠ¥ ì§€í‘œ
            f.write("Average Performance Metrics:\n")
            f.write(f"- F1 Score: {metrics['f1']:.4f}\n")
            f.write(f"- Direction Accuracy: {metrics['accuracy']:.2f}%\n")
            f.write(f"- MAPE: {metrics['mape']:.2f}%\n")
            f.write(f"- Weighted Score: {metrics['weighted_score']:.2f}%\n\n")
            
            # ë‚ ì§œë³„ ìƒì„¸ ì •ë³´
            f.write("Performance By Date:\n")
            for pred in all_preds:
                date = pred['date']
                m = pred['metrics']
                f.write(f"\n* {date}:\n")
                f.write(f"  - F1 Score: {m['f1']:.4f}\n")
                f.write(f"  - Accuracy: {m['accuracy']:.2f}%\n")
                f.write(f"  - MAPE: {m['mape']:.2f}%\n")
                f.write(f"  - Weighted Score: {m['weighted_score']:.2f}%\n")
                
                # êµ¬ë§¤ êµ¬ê°„ ì •ë³´
                if pred['interval_scores']:
                    best_interval = decide_purchase_interval(pred['interval_scores'])
                    f.write("Best Purchase Interval:\n")
                    f.write(f"- Start Date: {best_interval['start_date']}\n")
                    f.write(f"- End Date: {best_interval['end_date']}\n")
                    f.write(f"- Duration: {best_interval['days']} days\n")
                    f.write(f"- Average Price: {best_interval['avg_price']:.2f}\n")
                    f.write(f"- Score: {best_interval['score']}\n")
                    f.write(f"- Selection Reason: {best_interval.get('selection_reason', '')}\n\n")
        
        return report_filename
    
    except Exception as e:
        logger.error(f"Error generating accumulated report: {str(e)}")
        return None
    
def background_varmax_prediction(file_path, current_date, pred_days, use_cache=True):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ VARMAX ì˜ˆì¸¡ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    global prediction_state
    
    try:
        from app.utils.file_utils import set_seed
        from app.data.cache_manager import load_varmax_prediction, save_varmax_prediction
        from app.visualization.plotter import create_varmax_visualizations
        # ì¼ê´€ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ê³ ì •
        set_seed()
        # í˜„ì¬ íŒŒì¼ ìƒíƒœ ì—…ë°ì´íŠ¸
        prediction_state['current_file'] = file_path
        
        # ğŸ” ê¸°ì¡´ ì €ì¥ëœ ì˜ˆì¸¡ í™•ì¸ (use_cache=Trueì¸ ê²½ìš°)
        if use_cache:
            logger.info(f"ğŸ” [VARMAX_CACHE] Checking for existing prediction for date: {current_date}")
            existing_prediction = load_varmax_prediction(current_date)
            
            if existing_prediction:
                logger.info(f"âœ… [VARMAX_CACHE] Found existing VARMAX prediction for {current_date}")
                logger.info(f"ğŸ” [VARMAX_CACHE] Cached data keys: {list(existing_prediction.keys())}")
                logger.info(f"ğŸ” [VARMAX_CACHE] MA results available: {bool(existing_prediction.get('ma_results'))}")
                ma_results = existing_prediction.get('ma_results')
                if ma_results:
                    logger.info(f"ğŸ” [VARMAX_CACHE] MA results type: {type(ma_results)}")
                    if isinstance(ma_results, dict):
                        logger.info(f"ğŸ” [VARMAX_CACHE] MA results keys: {list(ma_results.keys())}")
                    else:
                        logger.warning(f"âš ï¸ [VARMAX_CACHE] MA results is not a dict: {type(ma_results)}")
                
                # ğŸ”‘ ìƒíƒœ ë³µì› (ìˆœì°¨ì ìœ¼ë¡œ)
                logger.info(f"ğŸ”„ [VARMAX_CACHE] Restoring state from cached prediction...")
                
                # ê¸°ì¡´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìƒíƒœì— ë¡œë“œ (ì•ˆì „í•œ íƒ€ì… ê²€ì‚¬)
                prediction_state['varmax_predictions'] = existing_prediction.get('predictions', [])
                prediction_state['varmax_half_month_averages'] = existing_prediction.get('half_month_averages', [])
                prediction_state['varmax_metrics'] = existing_prediction.get('metrics', {})
                
                # MA results ì•ˆì „í•œ ë¡œë“œ
                ma_results = existing_prediction.get('ma_results', {})
                if isinstance(ma_results, dict):
                    prediction_state['varmax_ma_results'] = ma_results
                else:
                    logger.warning(f"âš ï¸ [VARMAX_CACHE] Invalid ma_results type: {type(ma_results)}, setting empty dict")
                    prediction_state['varmax_ma_results'] = {}
                
                prediction_state['varmax_selected_features'] = existing_prediction.get('selected_features', [])
                prediction_state['varmax_current_date'] = existing_prediction.get('current_date', current_date)
                prediction_state['varmax_model_info'] = existing_prediction.get('model_info', {})
                prediction_state['varmax_plots'] = existing_prediction.get('plots', {})
                
                # ì¦‰ì‹œ ì™„ë£Œ ìƒíƒœë¡œ ì„¤ì •
                prediction_state['varmax_is_predicting'] = False
                prediction_state['varmax_prediction_progress'] = 100
                prediction_state['varmax_error'] = None
                
                logger.info(f"âœ… [VARMAX_CACHE] State restoration completed")
                
                logger.info(f"âœ… [VARMAX_CACHE] Successfully loaded existing prediction for {current_date}")
                logger.info(f"ğŸ” [VARMAX_CACHE] State restored - predictions: {len(prediction_state['varmax_predictions'])}, MA results: {len(prediction_state['varmax_ma_results'])}")
                
                # ğŸ” ìµœì¢… ê²€ì¦
                logger.info(f"ğŸ” [VARMAX_CACHE] Final verification - is_predicting: {prediction_state.get('varmax_is_predicting')}")
                logger.info(f"ğŸ” [VARMAX_CACHE] Final verification - predictions count: {len(prediction_state.get('varmax_predictions', []))}")
                logger.info(f"ğŸ” [VARMAX_CACHE] Final verification - ma_results count: {len(prediction_state.get('varmax_ma_results', {}))}")
                
                # ğŸ›¡ï¸ ìƒíƒœ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                time.sleep(1.0)
                
                logger.info(f"ğŸ¯ [VARMAX_CACHE] Cache loading process completed for {current_date}")
                return
        
        # ğŸš€ ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
        logger.info(f"ğŸš€ [VARMAX_NEW] Starting new VARMAX prediction for {current_date}")
        forecaster = VARMAXSemiMonthlyForecaster(file_path, pred_days=pred_days)
        prediction_state['varmax_is_predicting'] = True
        prediction_state['varmax_prediction_progress'] = 10
        prediction_state['varmax_prediction_start_time'] = time.time()  # VARMAX ì‹œì‘ ì‹œê°„ ê¸°ë¡
        prediction_state['varmax_error'] = None
        
        # VARMAX ì˜ˆì¸¡ ìˆ˜í–‰
        prediction_state['varmax_prediction_progress'] = 30
        logger.info(f"ğŸ”„ [VARMAX_NEW] Starting prediction generation (30% complete)")
        
        try:
            min_index = 1 # ì„ì‹œ ì¸ë±ìŠ¤
            logger.info(f"ğŸ”„ [VARMAX_NEW] Calling generate_predictions_varmax with current_date={current_date}, var_num={min_index+2}")
            
            # ì˜ˆì¸¡ ì§„í–‰ë¥ ì„ 30%ë¡œ ì„¤ì • (ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ)
            prediction_state['varmax_prediction_progress'] = 30

            mape_list=[]
            valid_indices = []
            for var_num in range(2,8):
                mape_value = forecaster.generate_variables_varmax(current_date, var_num)
                mape_list.append(mape_value)
                if mape_value is not None:
                    valid_indices.append(var_num - 2)  # ì¸ë±ìŠ¤ ì¡°ì •
                logger.info(f"Var {var_num} model MAPE: {mape_value}")
            
            # None ê°’ í•„í„°ë§
            valid_mape_values = [mape for mape in mape_list if mape is not None]
            
            if not valid_mape_values:
                raise Exception("All VARMAX variable models failed to generate valid MAPE values")
            
            # ìµœì†Œ MAPE ê°’ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            min_mape = min(valid_mape_values)
            min_index = None
            for i, mape in enumerate(mape_list):
                if mape == min_mape:
                    min_index = i
                    break
            
            logger.info(f"Var {min_index+2} model is selected, MAPE:{mape_list[min_index]}%")
            logger.info(f"Valid models: {len(valid_mape_values)}/{len(mape_list)}")
            
            results = forecaster.generate_predictions_varmax(current_date, min_index+2)
            logger.info(f"âœ… [VARMAX_NEW] Prediction generation completed successfully")
            
            # ìµœì¢… ì§„í–‰ë¥  95%ë¡œ ì„¤ì • (ì‹œê°í™” ìƒì„± ì „)
            prediction_state['varmax_prediction_progress'] = 95
            
        except Exception as prediction_error:
            logger.error(f"âŒ [VARMAX_NEW] Error during prediction generation: {str(prediction_error)}")
            logger.error(f"âŒ [VARMAX_NEW] Prediction error traceback: {traceback.format_exc()}")
            
            # ì˜ˆì¸¡ ì‹¤íŒ¨ ìƒíƒœë¡œ ì„¤ì •
            prediction_state['varmax_error'] = f"Prediction generation failed: {str(prediction_error)}"
            prediction_state['varmax_is_predicting'] = False
            prediction_state['varmax_prediction_progress'] = 0
            logger.error(f"âŒ [VARMAX_NEW] Prediction state reset due to error")
            return
        
        if results['success']:
            logger.info(f"ğŸ”„ [VARMAX_NEW] Updating state with new prediction results...")
            
            # ìƒíƒœì— ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ LSTM ê²°ê³¼ì™€ ë¶„ë¦¬)
            prediction_state['varmax_predictions'] = results['predictions']
            prediction_state['varmax_half_month_averages'] = results.get('half_month_averages', [])
            prediction_state['varmax_metrics'] = results['metrics']
            prediction_state['varmax_ma_results'] = results['ma_results']
            prediction_state['varmax_selected_features'] = results['selected_features']
            prediction_state['varmax_current_date'] = results['current_date']
            prediction_state['varmax_model_info'] = results['model_info']
            
            # ì‹œê°í™” ìƒì„± (ê¸°ì¡´ app.py ë°©ì‹ í™œìš©)
            plots_info = create_varmax_visualizations(results)
            prediction_state['varmax_plots'] = plots_info
            
            prediction_state['varmax_prediction_progress'] = 100
            prediction_state['varmax_is_predicting'] = False
            prediction_state['varmax_error'] = None
            
            # VARMAX ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            save_varmax_prediction(results, current_date)
            
            logger.info("âœ… [VARMAX_NEW] Prediction completed successfully")
            logger.info(f"ğŸ” [VARMAX_NEW] Final state - predictions: {len(prediction_state['varmax_predictions'])}")
        else:
            prediction_state['varmax_error'] = results['error']
            prediction_state['varmax_is_predicting'] = False
            prediction_state['varmax_prediction_progress'] = 0
            
    except Exception as e:
        logger.error(f"âŒ [VARMAX_BG] Error in background VARMAX prediction: {str(e)}")
        logger.error(f"âŒ [VARMAX_BG] Full traceback: {traceback.format_exc()}")
        
        # ì—ëŸ¬ ìƒíƒœë¡œ ì„¤ì •í•˜ê³  ìì„¸í•œ ë¡œê¹…
        prediction_state['varmax_error'] = f"Background prediction failed: {str(e)}"
        prediction_state['varmax_is_predicting'] = False
        prediction_state['varmax_prediction_progress'] = 0
        
        logger.error(f"âŒ [VARMAX_BG] VARMAX prediction failed completely. Current state reset.")
        logger.error(f"âŒ [VARMAX_BG] Error type: {type(e).__name__}")
        logger.error(f"âŒ [VARMAX_BG] Error details: {str(e)}")
        
        # ì—ëŸ¬ ë°œìƒ ì‹œ ëª¨ë“  VARMAX ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
        prediction_state['varmax_predictions'] = []
        prediction_state['varmax_metrics'] = {}
        prediction_state['varmax_ma_results'] = {}
        prediction_state['varmax_selected_features'] = []
        prediction_state['varmax_current_date'] = None
        prediction_state['varmax_model_info'] = {}
        prediction_state['varmax_plots'] = {}
        prediction_state['varmax_half_month_averages'] = []