import torch
import logging
import traceback
import time # get_detailed_gpu_utilizationì—ì„œ ì‚¬ìš©
import subprocess # get_detailed_gpu_utilizationì—ì„œ ì‚¬ìš©
import psutil # cleanup_excel_processesì—ì„œ ì‚¬ìš©

# logger ì •ì˜ ì¶”ê°€
logger = logging.getLogger(__name__)

def check_gpu_availability():
    """GPU ì‚¬ìš© ê°€ëŠ¥ì„± ë° í˜„ì¬ ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜"""
    try:
        logger.info("=" * 60)
        logger.info("ğŸ” GPU ë° ë””ë°”ì´ìŠ¤ ì •ë³´ í™•ì¸")
        logger.info("=" * 60)
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        cuda_available = torch.cuda.is_available()
        logger.info(f"ğŸ”§ CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
        
        if cuda_available:
            # GPU ê°œìˆ˜ ë° ì •ë³´
            gpu_count = torch.cuda.device_count()
            logger.info(f"ğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜: {gpu_count}")
            
            # ê° GPU ì •ë³´ ì¶œë ¥
            for i in range(gpu_count):
                try:
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_props = torch.cuda.get_device_properties(i)
                    gpu_memory = gpu_props.total_memory / 1024**3  # GB
                    
                    # ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (ì•ˆì „í•œ ë°©ë²•)
                    compute_capability = f"{getattr(gpu_props, 'major', 0)}.{getattr(gpu_props, 'minor', 0)}"
                    
                    logger.info(f"  ğŸ“± GPU {i}: {gpu_name} ({gpu_memory:.1f}GB, Compute {compute_capability})")
                    
                    # ë©€í‹°í”„ë¡œì„¸ì„œ ê°œìˆ˜ (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
                    if hasattr(gpu_props, 'multiprocessor_count'):
                        mp_count = gpu_props.multiprocessor_count
                        logger.info(f"    ğŸ”§ ë©€í‹°í”„ë¡œì„¸ì„œ: {mp_count}ê°œ")
                    elif hasattr(gpu_props, 'multi_processor_count'):
                        mp_count = gpu_props.multi_processor_count
                        logger.info(f"    ğŸ”§ ë©€í‹°í”„ë¡œì„¸ì„œ: {mp_count}ê°œ")
                        
                except Exception as e:
                    logger.warning(f"  âš ï¸ GPU {i} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                    logger.info(f"  ğŸ“± GPU {i}: ì •ë³´ í™•ì¸ ë¶ˆê°€")
            
            # í˜„ì¬ GPU ë””ë°”ì´ìŠ¤
            current_device = torch.cuda.current_device()
            current_gpu_name = torch.cuda.get_device_name(current_device)
            logger.info(f"ğŸ¯ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU: {current_device} ({current_gpu_name})")
            
                    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(current_device) / 1024**3
            cached = torch.cuda.memory_reserved(current_device) / 1024**3
            logger.info(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.2f}GB (í• ë‹¹) / {cached:.2f}GB (ìºì‹œ)")
            
            # ê°„ë‹¨í•œ GPU í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
            try:
                logger.info("ğŸ§ª GPU ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
                test_tensor = torch.randn(1000, 1000, device=current_device)
                test_result = torch.matmul(test_tensor, test_tensor.T)
                
                # í…ŒìŠ¤íŠ¸ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬í™•ì¸
                allocated_after = torch.cuda.memory_allocated(current_device) / 1024**3
                cached_after = torch.cuda.memory_reserved(current_device) / 1024**3
                logger.info(f"âœ… GPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ! í…ŒìŠ¤íŠ¸ í›„ ë©”ëª¨ë¦¬: {allocated_after:.2f}GB (í• ë‹¹) / {cached_after:.2f}GB (ìºì‹œ)")
                
                # í…ŒìŠ¤íŠ¸ í…ì„œ ì •ë¦¬
                del test_tensor, test_result
                torch.cuda.empty_cache()
                
                # ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ìƒíƒœ
                allocated_final = torch.cuda.memory_allocated(current_device) / 1024**3
                cached_final = torch.cuda.memory_reserved(current_device) / 1024**3
                logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ í›„: {allocated_final:.2f}GB (í• ë‹¹) / {cached_final:.2f}GB (ìºì‹œ)")
                
            except Exception as e:
                logger.error(f"âŒ GPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        
        # ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ê²°ì •
        device = torch.device('cuda' if cuda_available else 'cpu')
        logger.info(f"âš¡ ëª¨ë¸ í•™ìŠµ/ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {device}")
        
        # PyTorch ë²„ì „ ì •ë³´
        logger.info(f"ğŸ”¢ PyTorch ë²„ì „: {torch.__version__}")
        
        # CUDNN ì •ë³´ (CUDA ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if cuda_available:
            try:
                logger.info(f"ğŸ”§ cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
                logger.info(f"ğŸ”§ cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled}")
            except Exception as e:
                logger.warning(f"âš ï¸ cuDNN ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
                
            # GPU ì†ì„± ë””ë²„ê¹… ì •ë³´ (ì²« ë²ˆì§¸ GPUë§Œ)
            if gpu_count > 0:
                try:
                    props = torch.cuda.get_device_properties(0)
                    available_attrs = [attr for attr in dir(props) if not attr.startswith('_')]
                    logger.info(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ GPU ì†ì„±ë“¤: {available_attrs}")
                except Exception as e:
                    logger.warning(f"âš ï¸ GPU ì†ì„± í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        
        logger.info("=" * 60)
        
        return device, cuda_available
        
    except Exception as e:
        logger.error(f"âŒ GPU ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(traceback.format_exc())
        return torch.device('cpu'), False

def get_detailed_gpu_utilization():
    """nvidia-smië¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸í•œ GPU í™œìš©ë¥ ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    try:
        import subprocess
        
        # ê¸°ë³¸ í™œìš©ë¥  ì •ë³´
        basic_result = subprocess.run([
            'nvidia-smi', 
            '--query-gpu=utilization.gpu,utilization.memory,temperature.gpu,power.draw,power.limit',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, timeout=5)
        
        # ìƒì„¸ í™œìš©ë¥  ì •ë³´ (Encoder, Decoder ë“±)
        detailed_result = subprocess.run([
            'nvidia-smi', 
            '--query-gpu=utilization.gpu,utilization.memory,utilization.encoder,utilization.decoder',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, timeout=5)
        
        # ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì •ë³´
        process_result = subprocess.run([
            'nvidia-smi', 
            '--query-compute-apps=pid,process_name,used_gpu_memory',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True, timeout=5)
        
        gpu_stats = []
        
        if basic_result.returncode == 0 and basic_result.stdout.strip():
            basic_lines = basic_result.stdout.strip().split('\n')
            detailed_lines = detailed_result.stdout.strip().split('\n') if detailed_result.returncode == 0 else []
            
            for i, line in enumerate(basic_lines):
                parts = line.split(', ')
                if len(parts) >= 3:
                    gpu_util = parts[0].strip()
                    mem_util = parts[1].strip()
                    temp = parts[2].strip()
                    power_draw = parts[3].strip() if len(parts) > 3 else 'N/A'
                    power_limit = parts[4].strip() if len(parts) > 4 else 'N/A'
                    
                    # ìƒì„¸ ì •ë³´ ì¶”ê°€
                    encoder_util = 'N/A'
                    decoder_util = 'N/A'
                    
                    if i < len(detailed_lines):
                        detailed_parts = detailed_lines[i].split(', ')
                        if len(detailed_parts) >= 4:
                            encoder_util = detailed_parts[2].strip()
                            decoder_util = detailed_parts[3].strip()
                    
                    gpu_stat = {
                        'gpu_id': i,
                        'gpu_utilization': gpu_util,
                        'memory_utilization': mem_util,
                        'encoder_utilization': encoder_util,
                        'decoder_utilization': decoder_util,
                        'temperature': temp,
                        'power_draw': power_draw,
                        'power_limit': power_limit,
                        'measurement_method': 'nvidia-smi',
                        'timestamp': time.time()
                    }
                    
                    gpu_stats.append(gpu_stat)
        
        # ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì¶”ê°€
        if process_result.returncode == 0 and process_result.stdout.strip():
            process_lines = process_result.stdout.strip().split('\n')
            compute_processes = []
            for line in process_lines:
                parts = line.split(', ')
                if len(parts) >= 3:
                    compute_processes.append({
                        'pid': parts[0].strip(),
                        'name': parts[1].strip(),
                        'gpu_memory_mb': parts[2].strip()
                    })
            
            # ì²« ë²ˆì§¸ GPUì— í”„ë¡œì„¸ìŠ¤ ì •ë³´ ì¶”ê°€
            if gpu_stats:
                gpu_stats[0]['compute_processes'] = compute_processes
        
        return gpu_stats
        
    except Exception as e:
        logger.warning(f"âš ï¸ ìƒì„¸ GPU í™œìš©ë¥  í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        return None

def get_gpu_utilization():
    """nvidia-smië¥¼ ì‚¬ìš©í•˜ì—¬ GPU í™œìš©ë¥ ì„ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
    detailed_stats = get_detailed_gpu_utilization()
    if detailed_stats:
        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return [{
            'gpu_id': stat['gpu_id'],
            'gpu_utilization': stat['gpu_utilization'],
            'memory_utilization': stat['memory_utilization'],
            'temperature': stat['temperature'],
            'power_draw': stat['power_draw'],
            'power_limit': stat['power_limit']
        } for stat in detailed_stats]
    return None

def compare_gpu_monitoring_methods():
    """ë‹¤ì–‘í•œ GPU ëª¨ë‹ˆí„°ë§ ë°©ë²•ì„ ë¹„êµí•˜ëŠ” í•¨ìˆ˜"""
    comparison_results = {
        'nvidia_smi': None,
        'torch_cuda': None,
        'monitoring_notes': []
    }
    
    try:
        # nvidia-smi ê²°ê³¼
        nvidia_stats = get_detailed_gpu_utilization()
        if nvidia_stats:
            comparison_results['nvidia_smi'] = nvidia_stats[0]  # ì²« ë²ˆì§¸ GPU
            comparison_results['monitoring_notes'].append(
                "nvidia-smi: CUDA ì—°ì‚° í™œìš©ë¥  ì¸¡ì • (ML/AI ì‘ì—…ì— ì •í™•)"
            )
        
        # PyTorch CUDA ì •ë³´
        if torch.cuda.is_available():
            device_id = torch.cuda.current_device()
            allocated = torch.cuda.memory_allocated(device_id) / 1024**3
            cached = torch.cuda.memory_reserved(device_id) / 1024**3
            total = torch.cuda.get_device_properties(device_id).total_memory / 1024**3
            
            comparison_results['torch_cuda'] = {
                'allocated_memory_gb': round(allocated, 3),
                'cached_memory_gb': round(cached, 3),
                'total_memory_gb': round(total, 1),
                'memory_usage_percent': round((allocated / total) * 100, 2)
            }
            comparison_results['monitoring_notes'].append(
                "PyTorch CUDA: ì‹¤ì œ PyTorch í…ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"
            )
        
        comparison_results['monitoring_notes'].extend([
            "Windows ì‘ì—… ê´€ë¦¬ì: ì£¼ë¡œ 3D ê·¸ë˜í”½ ì—”ì§„ í™œìš©ë¥  (CUDAì™€ ë‹¤ë¦„)",
            "nvidia-smi GPU í™œìš©ë¥ : CUDA ì—°ì‚° í™œìš©ë¥  (ML/AI ì‘ì—…)",
            "nvidia-smi Encoder/Decoder: ë¹„ë””ì˜¤ ì¸ì½”ë”©/ë””ì½”ë”© í™œìš©ë¥ ",
            "ì¸¡ì • ì‹œì ì— ë”°ë¼ ìˆœê°„ì ì¸ ë³€í™”ê°€ í´ ìˆ˜ ìˆìŒ"
        ])
        
    except Exception as e:
        comparison_results['error'] = str(e)
    
    return comparison_results

def log_device_usage(device, context=""):
    """íŠ¹ì • ìƒí™©ì—ì„œì˜ ë””ë°”ì´ìŠ¤ ì‚¬ìš© ì •ë³´ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜"""
    try:
        context_str = f"[{context}] " if context else ""
        logger.info(f"ğŸ¯ {context_str}ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
        
        if device.type == 'cuda' and torch.cuda.is_available():
            device_id = device.index if device.index is not None else torch.cuda.current_device()
            allocated = torch.cuda.memory_allocated(device_id) / 1024**3
            cached = torch.cuda.memory_reserved(device_id) / 1024**3
            total = torch.cuda.get_device_properties(device_id).total_memory / 1024**3
            
            logger.info(f"ğŸ’¾ {context_str}GPU ë©”ëª¨ë¦¬: {allocated:.3f}GB ì‚¬ìš© / {total:.1f}GB ì „ì²´ (ìºì‹œ: {cached:.3f}GB)")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚° ë° ìƒíƒœ í‘œì‹œ
            usage_percentage = (allocated / total) * 100
            cache_percentage = (cached / total) * 100
            
            if allocated > 0.001:  # 1MB ì´ìƒ ì‚¬ìš© ì¤‘ì¸ ê²½ìš°
                logger.info(f"ğŸ“Š {context_str}ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {usage_percentage:.2f}% (ìºì‹œ: {cache_percentage:.2f}%)")
                
                if usage_percentage > 80:
                    logger.warning(f"âš ï¸ {context_str}GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {usage_percentage:.1f}%")
                elif usage_percentage > 50:
                    logger.info(f"ğŸ“ˆ {context_str}GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {usage_percentage:.1f}% (ì •ìƒ)")
            else:
                logger.info(f"ğŸ’­ {context_str}í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—†ìŒ (ëŒ€ê¸° ìƒíƒœ)")
            
            # GPU í™œìš©ë¥  í™•ì¸ (ìƒì„¸)
            detailed_stats = get_detailed_gpu_utilization()
            if detailed_stats and len(detailed_stats) > device_id:
                stat = detailed_stats[device_id]
                logger.info(f"âš¡ {context_str}CUDA í™œìš©ë¥ : {stat['gpu_utilization']}% (ë©”ëª¨ë¦¬: {stat['memory_utilization']}%)")
                logger.info(f"ğŸ¬ {context_str}Encoder: {stat['encoder_utilization']}%, Decoder: {stat['decoder_utilization']}%")
                logger.info(f"ğŸŒ¡ï¸ {context_str}GPU ì˜¨ë„: {stat['temperature']}Â°C, ì „ë ¥: {stat['power_draw']}/{stat['power_limit']}W")
                
                # ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì •ë³´
                if 'compute_processes' in stat and stat['compute_processes']:
                    process_count = len(stat['compute_processes'])
                    logger.info(f"ğŸ”„ {context_str}CUDA í”„ë¡œì„¸ìŠ¤: {process_count}ê°œ")
                    for proc in stat['compute_processes'][:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í‘œì‹œ
                        logger.info(f"    ğŸ“± PID {proc['pid']}: {proc['name']} ({proc['gpu_memory_mb']}MB)")
                
                # ë‚®ì€ í™œìš©ë¥  ë¶„ì„ ë° ì„¤ëª…
                try:
                    gpu_util_num = float(stat['gpu_utilization'])
                    if gpu_util_num < 10:
                        logger.warning(f"âš ï¸ {context_str}CUDA í™œìš©ë¥ ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤: {gpu_util_num}%")
                        logger.info(f"ğŸ’¡ {context_str}ì°¸ê³ : ì‘ì—… ê´€ë¦¬ìì˜ GPUëŠ” 3D ê·¸ë˜í”½ì„, nvidia-smiëŠ” CUDA ì—°ì‚°ì„ ì¸¡ì •í•©ë‹ˆë‹¤")
                        logger.info(f"ğŸ’¡ {context_str}ML/AI ì‘ì—…ì—ì„œëŠ” nvidia-smiì˜ CUDA í™œìš©ë¥ ì´ ì •í™•í•©ë‹ˆë‹¤")
                    elif gpu_util_num < 30:
                        logger.info(f"ğŸ“‰ {context_str}CUDA í™œìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤: {gpu_util_num}% - ë°°ì¹˜ í¬ê¸° ì¦ê°€ ê³ ë ¤")
                    else:
                        logger.info(f"âœ… {context_str}CUDA í™œìš©ë¥ ì´ ì–‘í˜¸í•©ë‹ˆë‹¤: {gpu_util_num}%")
                except:
                    pass
                
            # GPU í™œì„± í”„ë¡œì„¸ìŠ¤ ìˆ˜ í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                import subprocess
                result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,process_name,used_memory', '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0 and result.stdout.strip():
                    active_processes = len(result.stdout.strip().split('\n'))
                    logger.info(f"ğŸ”„ {context_str}GPUì—ì„œ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤: {active_processes}ê°œ")
            except:
                pass  # nvidia-smiê°€ ì—†ê±°ë‚˜ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
                
        elif device.type == 'cpu':
            logger.info(f"ğŸ–¥ï¸ {context_str}CPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘")
            
    except Exception as e:
        logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ì‚¬ìš© ì •ë³´ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {str(e)}")
