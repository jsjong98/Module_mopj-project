import matplotlib
matplotlib.use('Agg') # ì„œë²„ì—ì„œ GUI ë°±ì—”ë“œ ì‚¬ìš© ì•ˆ í•¨
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
import seaborn as sns
import pandas as pd
import numpy as np
import io
import base64
import os
import logging
from datetime import timedelta
import traceback
import logging

from app.data.cache_manager import get_file_cache_dirs
from app.utils.date_utils import format_date, is_holiday
from app.utils.serialization import safe_serialize_value

logger = logging.getLogger(__name__)

def get_global_y_range(original_df, test_dates, predict_window):
    """
    í…ŒìŠ¤íŠ¸ êµ¬ê°„ì˜ ëª¨ë“  MOPJ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì—­ yì¶• ë²”ìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        original_df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        test_dates: í…ŒìŠ¤íŠ¸ ë‚ ì§œ ë°°ì—´
        predict_window: ì˜ˆì¸¡ ê¸°ê°„
    
    Returns:
        tuple: (y_min, y_max) ì „ì—­ ë²”ìœ„ ê°’
    """
    # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ë°ì´í„° ì¶”ì¶œ
    test_values = []
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì‹¤ì œ ê°’ ìˆ˜ì§‘
    for date in test_dates:
        if date in original_df.index and not pd.isna(original_df.loc[date, 'MOPJ']):
            test_values.append(original_df.loc[date, 'MOPJ'])
    
    # ì•ˆì „ì¥ì¹˜: ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜
    if not test_values:
        return None, None
    
    # ìµœì†Œ/ìµœëŒ€ ê³„ì‚° (ì•½ê°„ì˜ ë§ˆì§„ ì¶”ê°€)
    y_min = min(test_values) * 0.95
    y_max = max(test_values) * 1.05
    
    return y_min, y_max

def plot_prediction_basic(sequence_df, prediction_start_date, start_day_value, 
                         f1, accuracy, mape, weighted_score_pct, 
                         current_date=None,  # ğŸ”‘ ì¶”ê°€: ë°ì´í„° ì»·ì˜¤í”„ ë‚ ì§œ
                         save_prefix=None, title_prefix="Basic Prediction Graph",
                         y_min=None, y_max=None, file_path=None):
    """
    ê¸°ë³¸ ì˜ˆì¸¡ ê·¸ë˜í”„ ì‹œê°í™” - ê³¼ê±°/ë¯¸ë˜ ëª…í™• êµ¬ë¶„
    ğŸ”‘ current_date ì´í›„ëŠ” ë¯¸ë˜ ì˜ˆì¸¡ìœ¼ë¡œë§Œ í‘œì‹œ (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
    """
    
    fig = None
    
    try:
        logger.info(f"Creating prediction graph for prediction starting {format_date(prediction_start_date)}")
        
        # ğŸ“ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì • (íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        if save_prefix is None:
            try:
                cache_dirs = get_file_cache_dirs(file_path)
                save_dir = cache_dirs['plots']
            except Exception as e:
                logger.warning(f"Could not get cache directories for plots: {str(e)}")
                save_dir = Path("temp_plots")
                save_dir.mkdir(parents=True, exist_ok=True)
        else:
            save_dir = Path(save_prefix)
            save_dir.mkdir(parents=True, exist_ok=True)
        
        # DataFrameì˜ ë‚ ì§œ ì—´ì´ ë¬¸ìì—´ì¸ ê²½ìš° ë‚ ì§œ ê°ì²´ë¡œ ë³€í™˜
        if 'Date' in sequence_df.columns and isinstance(sequence_df['Date'].iloc[0], str):
            sequence_df['Date'] = pd.to_datetime(sequence_df['Date'])
        
        # âœ… current_date ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±°/ë¯¸ë˜ ë¶„í• 
        if current_date is not None:
            current_date = pd.to_datetime(current_date)
            
            # ê³¼ê±° ë°ì´í„° (current_date ì´ì „): ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ëª¨ë‘ í‘œì‹œ ê°€ëŠ¥
            past_df = sequence_df[sequence_df['Date'] <= current_date].copy()
            # ë¯¸ë˜ ë°ì´í„° (current_date ì´í›„): ì˜ˆì¸¡ê°’ë§Œ í‘œì‹œ
            future_df = sequence_df[sequence_df['Date'] > current_date].copy()
            
            # ê³¼ê±° ë°ì´í„°ì—ì„œ ì‹¤ì œê°’ì´ ìˆëŠ” ê²ƒë§Œ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©
            valid_df = past_df.dropna(subset=['Actual']) if 'Actual' in past_df.columns else pd.DataFrame()
            
            logger.info(f"  ğŸ“Š Data split - Past: {len(past_df)}, Future: {len(future_df)}, Validation: {len(valid_df)}")
        else:
            # current_dateê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
            valid_df = sequence_df.dropna(subset=['Actual']) if 'Actual' in sequence_df.columns else pd.DataFrame()
            future_df = sequence_df
            past_df = valid_df
        
        pred_df = sequence_df.dropna(subset=['Prediction'])
        
        # ê·¸ë˜í”„ ìƒì„±
        fig = plt.figure(figsize=(16, 9))
        plt.subplots_adjust(top=0.85)
        gs = GridSpec(2, 1, height_ratios=[3, 1], hspace=0.3, figure=fig)
        
        # ê·¸ë˜í”„ íƒ€ì´í‹€ê³¼ ì„œë¸Œíƒ€ì´í‹€
        if isinstance(prediction_start_date, str):
            main_title = f"{title_prefix} - Start: {prediction_start_date}"
        else:
            main_title = f"{title_prefix} - Start: {prediction_start_date.strftime('%Y-%m-%d')}"
        
        # âœ… ê³¼ê±°/ë¯¸ë˜ êµ¬ë¶„ ì •ë³´ê°€ í¬í•¨ëœ ì„œë¸Œíƒ€ì´í‹€
        if current_date is not None:
            validation_count = len(valid_df)
            future_count = len(future_df)
            subtitle = f"Data Cutoff: {current_date.strftime('%Y-%m-%d')} | Validation: {validation_count} pts | Future: {future_count} pts"
            if validation_count > 0:
                subtitle += f" | F1: {f1:.3f}, Acc: {accuracy:.1f}%, MAPE: {mape:.1f}%"
        else:
            # ê¸°ì¡´ ë°©ì‹
            if f1 == 0 and accuracy == 0 and mape == 0 and weighted_score_pct == 0:
                subtitle = "Future Prediction Only (No Validation Data Available)"
            else:
                subtitle = f"F1: {f1:.2f}, Acc: {accuracy:.2f}%, MAPE: {mape:.2f}%, Score: {weighted_score_pct:.2f}%"

        fig.text(0.5, 0.94, main_title, ha='center', fontsize=14, weight='bold')
        fig.text(0.5, 0.90, subtitle, ha='center', fontsize=12)
        
        # (1) ìƒë‹¨: ê°€ê²© ì˜ˆì¸¡ ê·¸ë˜í”„
        ax1 = fig.add_subplot(gs[0])
        ax1.set_title("Price Prediction: Past Validation vs Future Forecast", fontsize=13)
        ax1.grid(True, linestyle='--', alpha=0.5)

        if y_min is not None and y_max is not None:
            ax1.set_ylim(y_min, y_max)
        
        # ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ ì²˜ë¦¬
        if isinstance(prediction_start_date, str):
            start_date = pd.to_datetime(prediction_start_date)
        else:
            start_date = prediction_start_date
        
        # ì‹œì‘ì¼ ì´ì „ ë‚ ì§œ ê³„ì‚° (ì—°ê²°ì ìš©)
        prev_date = start_date - pd.Timedelta(days=1)
        while prev_date.weekday() >= 5 or is_holiday(prev_date):
            prev_date -= pd.Timedelta(days=1)
        
        # âœ… 1. ê³¼ê±° ì‹¤ì œê°’ (íŒŒë€ìƒ‰ ì‹¤ì„ ) - ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì¤€ì„ 
        if not valid_df.empty:
            real_dates = [prev_date] + valid_df['Date'].tolist()
            real_values = [start_day_value] + valid_df['Actual'].tolist()
            ax1.plot(real_dates, real_values, marker='o', color='blue', 
                    label='Actual (Past)', linewidth=2.5, markersize=5, zorder=3)
        
        # âœ… 2. ê³¼ê±° ì˜ˆì¸¡ê°’ (íšŒìƒ‰ ì ì„ ) - ëª¨ë¸ ì„±ëŠ¥ í™•ì¸ìš©
        if not valid_df.empty:
            past_pred_dates = [prev_date] + valid_df['Date'].tolist()
            past_pred_values = [start_day_value] + valid_df['Prediction'].tolist()
            ax1.plot(past_pred_dates, past_pred_values, marker='x', color='gray', 
                    label='Predicted (Past)', linewidth=1.5, linestyle=':', markersize=4, alpha=0.8, zorder=2)
        
        # âœ… 3. ë¯¸ë˜ ì˜ˆì¸¡ê°’ (ë¹¨ê°„ìƒ‰ ì ì„ ) - í•µì‹¬ ì˜ˆì¸¡
        if not future_df.empty:
            future_dates = future_df['Date'].tolist()
            future_values = future_df['Prediction'].tolist()
            
            # ì—°ê²°ì„  (ë§ˆì§€ë§‰ ì‹¤ì œê°’ â†’ ì²« ë¯¸ë˜ ì˜ˆì¸¡ê°’)
            if not valid_df.empty and future_dates:
                # ë§ˆì§€ë§‰ ê²€ì¦ ë°ì´í„°ì˜ ì‹¤ì œê°’ì—ì„œ ì²« ë¯¸ë˜ ì˜ˆì¸¡ìœ¼ë¡œ ì—°ê²°
                connection_x = [valid_df['Date'].iloc[-1], future_dates[0]]
                connection_y = [valid_df['Actual'].iloc[-1], future_values[0]]
                ax1.plot(connection_x, connection_y, '--', color='orange', alpha=0.6, linewidth=1.5, zorder=1)
            elif start_day_value is not None and future_dates:
                # ê²€ì¦ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹œì‘ê°’ì—ì„œ ì—°ê²°
                connection_x = [prev_date, future_dates[0]]
                connection_y = [start_day_value, future_values[0]]
                ax1.plot(connection_x, connection_y, '--', color='orange', alpha=0.6, linewidth=1.5, zorder=1)
            
            ax1.plot(future_dates, future_values, marker='o', color='red', 
                    label='Predicted (Future)', linewidth=2.5, linestyle='--', markersize=5, zorder=3)
        
        # âœ… 4. ë°ì´í„° ì»·ì˜¤í”„ ë¼ì¸ (ì´ˆë¡ìƒ‰ ì„¸ë¡œì„ )
        if current_date is not None:
            ax1.axvline(x=current_date, color='green', linestyle='-', alpha=0.8, 
                       linewidth=2.5, label=f'Data Cutoff', zorder=4)
            
            # ì»·ì˜¤í”„ ë‚ ì§œ í…ìŠ¤íŠ¸ ì¶”ê°€
            ax1.text(current_date, ax1.get_ylim()[1] * 0.95, 
                    f'{current_date.strftime("%m/%d")}', 
                    ha='center', va='top', fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgreen', alpha=0.7))
        else:
            # ì˜ˆì¸¡ ì‹œì‘ì ì— ìˆ˜ì§ì„  í‘œì‹œ (ê¸°ì¡´ ë°©ì‹)
            ax1.axvline(x=start_date, color='green', linestyle='--', alpha=0.7, 
                       linewidth=2, label='Prediction Start', zorder=4)
        
        # âœ… 5. ë°°ê²½ ìƒ‰ì¹  (ë°©í–¥ì„± ì¼ì¹˜ ì—¬ë¶€) - ê²€ì¦ ë°ì´í„°ë§Œ
        if not valid_df.empty and len(valid_df) > 1:
            for i in range(len(valid_df) - 1):
                curr_date = valid_df['Date'].iloc[i]
                next_date = valid_df['Date'].iloc[i + 1]
                
                curr_actual = valid_df['Actual'].iloc[i]
                next_actual = valid_df['Actual'].iloc[i + 1]
                curr_pred = valid_df['Prediction'].iloc[i]
                next_pred = valid_df['Prediction'].iloc[i + 1]
                
                # ë°©í–¥ ê³„ì‚°
                actual_dir = np.sign(next_actual - curr_actual)
                pred_dir = np.sign(next_pred - curr_pred)
                
                # ë°©í–¥ ì¼ì¹˜ ì—¬ë¶€ì— ë”°ë¥¸ ìƒ‰ìƒ
                color = 'lightblue' if actual_dir == pred_dir else 'lightcoral'
                ax1.axvspan(curr_date, next_date, color=color, alpha=0.15, zorder=0)
        
        ax1.set_xlabel("")
        ax1.set_ylabel("Price (USD/MT)", fontsize=11)
        ax1.legend(loc='upper left', fontsize=10)
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
        
        # âœ… (2) í•˜ë‹¨: ì˜¤ì°¨ ë¶„ì„ - ê²€ì¦ ë°ì´í„°ë§Œ ë˜ëŠ” ë³€í™”ëŸ‰
        ax2 = fig.add_subplot(gs[1])
        ax2.grid(True, linestyle='--', alpha=0.5)
        
        if not valid_df.empty and len(valid_df) > 0:
            # ê²€ì¦ ë°ì´í„°ì˜ ì ˆëŒ€ ì˜¤ì°¨
            error_dates = valid_df['Date'].tolist()
            error_values = [abs(row['Actual'] - row['Prediction']) for _, row in valid_df.iterrows()]
            
            if error_dates and error_values:
                bars = ax2.bar(error_dates, error_values, width=0.6, color='salmon', alpha=0.7, edgecolor='darkred', linewidth=0.5)
                ax2.set_title(f"Prediction Error - Validation Period ({len(error_dates)} points)", fontsize=11)
                
                # í‰ê·  ì˜¤ì°¨ ë¼ì¸
                avg_error = np.mean(error_values)
                ax2.axhline(y=avg_error, color='red', linestyle='--', alpha=0.8, 
                           label=f'Avg Error: {avg_error:.2f}')
                ax2.legend(fontsize=9)
            else:
                ax2.text(0.5, 0.5, "No validation errors to display", 
                        ha='center', va='center', transform=ax2.transAxes, fontsize=10)
                ax2.set_title("Error Analysis")
        else:
            # ì‹¤ì œê°’ì´ ì—†ëŠ” ê²½ìš°: ë¯¸ë˜ ì˜ˆì¸¡ì˜ ì¼ì¼ ë³€í™”ëŸ‰ í‘œì‹œ
            if not future_df.empty and len(future_df) > 1:
                change_dates = future_df['Date'].iloc[1:].tolist()
                change_values = np.diff(future_df['Prediction'].values)
                
                # ìƒìŠ¹/í•˜ë½ì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„
                colors = ['green' if change >= 0 else 'red' for change in change_values]
                
                bars = ax2.bar(change_dates, change_values, width=0.6, color=colors, alpha=0.7)
                ax2.set_title("Daily Price Changes - Future Predictions", fontsize=11)
                ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5, linewidth=1)
                
                # ë²”ë¡€ ì¶”ê°€
                from matplotlib.patches import Patch
                legend_elements = [Patch(facecolor='green', alpha=0.7, label='Price Up'),
                                 Patch(facecolor='red', alpha=0.7, label='Price Down')]
                ax2.legend(handles=legend_elements, fontsize=9)
            else:
                ax2.text(0.5, 0.5, "Insufficient data for change analysis", 
                        ha='center', va='center', transform=ax2.transAxes, fontsize=10)
                ax2.set_title("Change Analysis")
        
        ax2.set_xlabel("Date", fontsize=11)
        ax2.set_ylabel("Value", fontsize=11)
        ax2.xaxis.set_major_locator(mdates.AutoDateLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        plt.tight_layout()
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        if isinstance(prediction_start_date, str):
            date_str = pd.to_datetime(prediction_start_date).strftime('%Y%m%d')
        else:
            date_str = prediction_start_date.strftime('%Y%m%d')
        
        filename = f"prediction_start_{date_str}.png"
        full_path = save_dir / filename
        
        # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
        img_buf = io.BytesIO()
        plt.savefig(img_buf, format='png', dpi=300, bbox_inches='tight')
        img_buf.seek(0)
        
        # Base64ë¡œ ì¸ì½”ë”©
        img_str = base64.b64encode(img_buf.read()).decode('utf-8')
        
        # íŒŒì¼ë¡œ ì €ì¥
        plt.savefig(str(full_path), dpi=300, bbox_inches='tight')
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        plt.close(fig)
        plt.clf()
        img_buf.close()
        
        logger.info(f"Enhanced prediction graph saved: {full_path}")
        logger.info(f"  - Past validation points: {len(valid_df) if not valid_df.empty else 0}")
        logger.info(f"  - Future prediction points: {len(future_df) if not future_df.empty else 0}")
        
        return str(full_path), img_str
        
    except Exception as e:
        if fig is not None:
            plt.close(fig)
        plt.close('all')
        plt.clf()
        
        logger.error(f"Error in enhanced graph creation: {str(e)}")
        logger.error(traceback.format_exc())
        return None, None
    
def plot_moving_average_analysis(ma_results, sequence_start_date, save_prefix=None,
                               title_prefix="Moving Average Analysis", y_min=None, y_max=None, file_path=None):
    """ì´ë™í‰ê·  ë¶„ì„ ì‹œê°í™”"""
    try:
        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not ma_results or len(ma_results) == 0:
            logger.warning("No moving average results to plot")
            return None, None
            
        # ma_results í˜•ì‹: {'ma5': [{'date': '...', 'prediction': X, 'actual': Y, 'ma': Z}, ...], 'ma10': [...]}
        windows = sorted(ma_results.keys())
        
        if len(windows) == 0:
            logger.warning("No moving average windows found")
            return None, None
        
        # ìœ íš¨í•œ ìœˆë„ìš° í•„í„°ë§
        valid_windows = []
        for window_key in windows:
            if window_key in ma_results and ma_results[window_key] and len(ma_results[window_key]) > 0:
                valid_windows.append(window_key)
        
        if len(valid_windows) == 0:
            logger.warning("No valid moving average data found")
            return None, None
        
        fig = plt.figure(figsize=(12, max(4, 4 * len(valid_windows))))
        
        if isinstance(sequence_start_date, str):
            title = f"{title_prefix} Starting {sequence_start_date}"
        else:
            title = f"{title_prefix} Starting {sequence_start_date.strftime('%Y-%m-%d')}"
            
        fig.suptitle(title, fontsize=16)
        
        for idx, window_key in enumerate(valid_windows):
            window_num = window_key.replace('ma', '')
            ax = fig.add_subplot(len(valid_windows), 1, idx+1)
            
            window_data = ma_results[window_key]
            
            # ë°ì´í„° ê²€ì¦
            if not window_data or len(window_data) == 0:
                ax.text(0.5, 0.5, f"No data for {window_key}", 
                       ha='center', va='center', transform=ax.transAxes)
                continue
            
            # ë‚ ì§œ, ì˜ˆì¸¡, ì‹¤ì œê°’, MA ì¶”ì¶œ
            dates = []
            predictions = []
            actuals = []
            ma_preds = []
            
            for item in window_data:
                try:
                    # ì•ˆì „í•œ ë°ì´í„° ì¶”ì¶œ
                    if isinstance(item['date'], str):
                        dates.append(pd.to_datetime(item['date']))
                    else:
                        dates.append(item['date'])
                    
                    # None ê°’ ì²˜ë¦¬
                    predictions.append(item.get('prediction', 0))
                    actuals.append(item.get('actual', None))
                    ma_preds.append(item.get('ma', None))
                except Exception as e:
                    logger.warning(f"Error processing MA data item: {str(e)}")
                    continue
            
            if len(dates) == 0:
                ax.text(0.5, 0.5, f"No valid data for {window_key}", 
                       ha='center', va='center', transform=ax.transAxes)
                continue
            
            # yì¶• ë²”ìœ„ ì„¤ì •
            if y_min is not None and y_max is not None:
                ax.set_ylim(y_min, y_max)
            
            # ì›ë³¸ ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (ì˜…ê²Œ)
            ax.plot(dates, actuals, marker='o', color='blue', alpha=0.3, label='Actual')
            ax.plot(dates, predictions, marker='o', color='red', alpha=0.3, label='Predicted')
            
            # ì´ë™í‰ê· 
            # ì‹¤ì œê°’(actuals)ê³¼ ì´ë™í‰ê· (ma_preds) ëª¨ë‘ Noneì´ ì•„ë‹Œ ì¸ë±ìŠ¤ë¥¼ ì„ íƒ
            valid_indices = [
                i for i in range(len(ma_preds))
                if (ma_preds[i] is not None and actuals[i] is not None)
            ]

            if valid_indices:
                valid_dates = [dates[i] for i in valid_indices]
                valid_ma = [ma_preds[i] for i in valid_indices]
                valid_actuals = [actuals[i] for i in valid_indices]
                
                # ë°°ì—´ë¡œ ë³€í™˜
                valid_actuals_arr = np.array(valid_actuals)
                valid_ma_arr = np.array(valid_ma)
                
                # ì‹¤ì œê°’ì´ 0ì¸ í•­ëª©ì€ ì œì™¸í•˜ì—¬ MAPE ê³„ì‚°
                non_zero_mask = valid_actuals_arr != 0
                if np.sum(non_zero_mask) > 0:
                    ma_mape = np.mean(np.abs((valid_actuals_arr[non_zero_mask] - valid_ma_arr[non_zero_mask]) /
                                           valid_actuals_arr[non_zero_mask])) * 100
                else:
                    ma_mape = 0.0
                
                ax.set_title(f"MA-{window_num} Analysis (MAPE: {ma_mape:.2f}%, Count: {len(valid_indices)})")
            else:
                ax.set_title(f"MA-{window_num} Analysis (Insufficient data)")
            
            ax.legend()
            ax.grid(True, linestyle='--', alpha=0.5)
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
            ax.set_xlabel("Date")
            ax.set_ylabel("Price")
        
        plt.tight_layout()
        
        # ğŸ“ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì • (íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
        if save_prefix is None:
            try:
                cache_dirs = get_file_cache_dirs(file_path)
                save_dir = cache_dirs['ma_plots']
            except Exception as e:
                logger.warning(f"Could not get cache directories for MA plots: {str(e)}")
                save_dir = Path("temp_ma_plots")
                save_dir.mkdir(parents=True, exist_ok=True)
        else:
            save_dir = Path(save_prefix)
            save_dir.mkdir(parents=True, exist_ok=True)
        
        if isinstance(sequence_start_date, str):
            date_str = pd.to_datetime(sequence_start_date).strftime('%Y%m%d')
        else:
            date_str = sequence_start_date.strftime('%Y%m%d')
            
        filename = save_dir / f"ma_analysis_{date_str}.png"
        
        # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
        img_buf = io.BytesIO()
        plt.savefig(img_buf, format='png', dpi=300)
        img_buf.seek(0)
        
        # Base64ë¡œ ì¸ì½”ë”©
        img_str = base64.b64encode(img_buf.read()).decode('utf-8')
        
        # íŒŒì¼ ì €ì¥
        plt.savefig(str(filename), dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Moving Average graph saved: {filename}")
        return str(filename), img_str
        
    except Exception as e:
        logger.error(f"Error in moving average visualization: {str(e)}")
        logger.error(traceback.format_exc())
        return None, None
    
def visualize_accumulated_metrics():
    """ëˆ„ì  ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    global prediction_state
    
    if not prediction_state['accumulated_predictions']:
        return None, None
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        dates = []
        f1_scores = []
        accuracies = []
        mapes = []
        weighted_scores = []
        
        for pred in prediction_state['accumulated_predictions']:
            dates.append(pred['date'])
            m = pred['metrics']
            f1_scores.append(m['f1'])
            accuracies.append(m['accuracy'])
            mapes.append(m['mape'])
            weighted_scores.append(m['weighted_score'])
        
        # ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        dates = [pd.to_datetime(d) for d in dates]
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, axs = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Accumulated Prediction Metrics', fontsize=16)
        
        # F1 Score
        axs[0, 0].plot(dates, f1_scores, marker='o', color='blue')
        axs[0, 0].set_title('F1 Score')
        axs[0, 0].set_ylim(0, 1)
        axs[0, 0].grid(True)
        plt.setp(axs[0, 0].xaxis.get_majorticklabels(), rotation=45)
        
        # Accuracy
        axs[0, 1].plot(dates, accuracies, marker='o', color='green')
        axs[0, 1].set_title('Direction Accuracy (%)')
        axs[0, 1].set_ylim(0, 100)
        axs[0, 1].grid(True)
        plt.setp(axs[0, 1].xaxis.get_majorticklabels(), rotation=45)
        
        # MAPE
        axs[1, 0].plot(dates, mapes, marker='o', color='red')
        axs[1, 0].set_title('MAPE (%)')
        axs[1, 0].set_ylim(0, max(mapes) * 1.2)
        axs[1, 0].grid(True)
        plt.setp(axs[1, 0].xaxis.get_majorticklabels(), rotation=45)
        
        # Weighted Score
        axs[1, 1].plot(dates, weighted_scores, marker='o', color='purple')
        axs[1, 1].set_title('Weighted Score (%)')
        axs[1, 1].set_ylim(0, 100)
        axs[1, 1].grid(True)
        plt.setp(axs[1, 1].xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ ì €ì¥
        img_buf = io.BytesIO()
        plt.savefig(img_buf, format='png', dpi=300)
        img_buf.seek(0)
        
        # Base64ë¡œ ì¸ì½”ë”©
        img_str = base64.b64encode(img_buf.read()).decode('utf-8')
        
        # íŒŒì¼ë¡œ ì €ì¥ - íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        try:
            cache_dirs = get_file_cache_dirs()
            plots_dir = cache_dirs['plots']
            filename = os.path.join(plots_dir, 'accumulated_metrics.png')
        except Exception as e:
            logger.warning(f"Could not get cache directories for accumulated metrics: {str(e)}")
            filename = 'accumulated_metrics.png'
        
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        return filename, img_str
        
    except Exception as e:
        logger.error(f"Error visualizing accumulated metrics: {str(e)}")
        return None, None
    
def plot_varmax_prediction_basic(sequence_df, sequence_start_date, start_day_value, 
                                f1, accuracy, mape, weighted_score, 
                                save_prefix=None, title_prefix="VARMAX Semi-monthly Prediction", file_path=None):
    """VARMAX ê¸°ë³¸ ì˜ˆì¸¡ ê·¸ë˜í”„ ì‹œê°í™” (ê¸°ì¡´ plot_prediction_basicê³¼ ë™ì¼í•œ ìŠ¤íƒ€ì¼)"""
    try:
        logger.info(f"Creating VARMAX prediction graph for {sequence_start_date}")
        
        # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        if save_prefix is None:
            cache_dirs = get_file_cache_dirs(file_path)
            save_prefix = cache_dirs['plots']
        
        # ì˜ˆì¸¡ê°’ë§Œ ìˆëŠ” ë°ì´í„° ì²˜ë¦¬
        pred_df = sequence_df.dropna(subset=['Prediction'])
        valid_df = sequence_df.dropna(subset=['Actual']) if 'Actual' in sequence_df.columns else pd.DataFrame()
        
        # ê·¸ë˜í”„ ìƒì„±
        fig = plt.figure(figsize=(16, 9))
        plt.subplots_adjust(top=0.85)
        gs = GridSpec(2, 1, height_ratios=[3, 1], hspace=0.3, figure=fig)
        
        # ì œëª© ì„¤ì •
        main_title = f"{title_prefix} - {sequence_start_date}"
        subtitle = f"F1: {f1:.2f}, Acc: {accuracy:.2f}%, MAPE: {mape:.2f}%, Score: {weighted_score:.2f}%"
        
        fig.text(0.5, 0.94, main_title, ha='center', fontsize=14, weight='bold')
        fig.text(0.5, 0.90, subtitle, ha='center', fontsize=12)
        
        # ìƒë‹¨: ì˜ˆì¸¡ vs ì‹¤ì œ (ìˆëŠ” ê²½ìš°)
        ax1 = fig.add_subplot(gs[0])
        ax1.set_title("VARMAX Long-term Prediction")
        ax1.grid(True, linestyle='--', alpha=0.5)
        
        # ì˜ˆì¸¡ê°’ í”Œë¡¯
        ax1.plot(pred_df['Date'], pred_df['Prediction'],
                marker='o', color='red', label='VARMAX Predicted', linewidth=2)
        
        # ì‹¤ì œê°’ í”Œë¡¯ (ìˆëŠ” ê²½ìš°)
        if len(valid_df) > 0:
            ax1.plot(valid_df['Date'], valid_df['Actual'],
                    marker='o', color='blue', label='Actual', linewidth=2)
            
            # ë°©í–¥ì„± ì¼ì¹˜ ì—¬ë¶€ ë°°ê²½ ìƒ‰ì¹ 
            for i in range(1, len(valid_df)):
                if i < len(pred_df):
                    actual_dir = np.sign(valid_df['Actual'].iloc[i] - valid_df['Actual'].iloc[i-1])
                    pred_dir = np.sign(pred_df['Prediction'].iloc[i] - pred_df['Prediction'].iloc[i-1])
                    color = 'blue' if actual_dir == pred_dir else 'red'
                    ax1.axvspan(valid_df['Date'].iloc[i-1], valid_df['Date'].iloc[i], alpha=0.1, color=color)
        
        ax1.set_xlabel("Date")
        ax1.set_ylabel("MOPJ Price")
        ax1.legend()
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
        
        # í•˜ë‹¨: ì˜¤ì°¨ (ì‹¤ì œê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ)
        ax2 = fig.add_subplot(gs[1])
        ax2.grid(True, linestyle='--', alpha=0.5)
        
        if len(valid_df) > 0:
            # ì˜¤ì°¨ ê³„ì‚° ë° í”Œë¡¯
            errors = valid_df['Actual'] - valid_df['Prediction']
            ax2.bar(valid_df['Date'], errors, alpha=0.7, color='orange', width=0.8)
            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.8)
            ax2.set_title(f"Prediction Error (MAE: {abs(errors).mean():.2f})")
        else:
            ax2.text(0.5, 0.5, 'No actual data for error calculation', 
                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)
            ax2.set_title("Prediction Error (No validation data)")
        
        ax2.set_xlabel("Date")
        ax2.set_ylabel("Error")
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
        
        # íŒŒì¼ ì €ì¥
        os.makedirs(save_prefix, exist_ok=True)
        filename = f"varmax_prediction_{sequence_start_date}.png"
        filepath = os.path.join(save_prefix, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"VARMAX prediction graph saved: {filepath}")
        return filepath
        
    except Exception as e:
        logger.error(f"Error creating VARMAX prediction graph: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def create_varmax_visualizations(results):
    """VARMAX ê²°ê³¼ì— ëŒ€í•œ ì‹œê°í™” ìƒì„±"""
    try:
        # ê¸°ë³¸ ì˜ˆì¸¡ ê·¸ë˜í”„
        sequence_df = pd.DataFrame(results['predictions'])
        sequence_df['Date'] = pd.to_datetime(sequence_df['Date'])
        
        metrics = results['metrics']
        current_date = results['current_date']
        start_day_value = sequence_df['Prediction'].iloc[0] if len(sequence_df) > 0 else 0
        
        # ê¸°ë³¸ ê·¸ë˜í”„
        basic_plot = plot_varmax_prediction_basic(
            sequence_df, current_date, start_day_value,
            metrics['f1'], metrics['accuracy'], metrics['mape'], metrics['weighted_score']
        )
        
        # ì´ë™í‰ê·  ê·¸ë˜í”„
        ma_plot = plot_varmax_moving_average_analysis(
            results['ma_results'], current_date
        )
        
        plots_info = {
            'basic_plot': basic_plot,
            'ma_plot': ma_plot
        }
        
        logger.info("VARMAX visualizations created successfully")
        return plots_info
        
    except Exception as e:
        logger.error(f"Error creating VARMAX visualizations: {str(e)}")
        logger.error(traceback.format_exc())
        return {}

def plot_varmax_moving_average_analysis(ma_results, sequence_start_date, save_prefix=None,
                                        title_prefix="VARMAX Moving Average Analysis", file_path=None):
    """VARMAX ì´ë™í‰ê·  ë¶„ì„ ê·¸ë˜í”„"""
    try:
        logger.info(f"Creating VARMAX moving average analysis for {sequence_start_date}")
        
        # íŒŒì¼ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        if save_prefix is None:
            cache_dirs = get_file_cache_dirs(file_path)
            save_prefix = cache_dirs['ma_plots']
        
        if not ma_results:
            logger.warning("No moving average results to plot")
            return None
        
        windows = list(ma_results.keys())
        n_windows = len(windows)
        
        if n_windows == 0:
            logger.warning("No moving average windows found")
            return None
        
        # ê·¸ë˜í”„ ìƒì„± (2x2 ê·¸ë¦¬ë“œë¡œ ìµœëŒ€ 4ê°œ ìœˆë„ìš° í‘œì‹œ)
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f"{title_prefix} - {sequence_start_date}", fontsize=16, weight='bold')
        axes = axes.flatten()
        
        for i, window in enumerate(windows[:4]):  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
            ax = axes[i]
            ma_data = ma_results[window]
            
            if not ma_data:
                ax.text(0.5, 0.5, f'No data for {window}', ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f"{window} (No Data)")
                continue
            
            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(ma_data)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            
            # ì˜ˆì¸¡ê°’ê³¼ ì´ë™í‰ê·  í”Œë¡¯
            ax.plot(df['date'], df['prediction'], marker='o', color='red', 
                   label='Prediction', linewidth=2, markersize=4)
            ax.plot(df['date'], df['ma'], marker='s', color='blue', 
                   label=f'MA-{window.replace("ma", "")}', linewidth=2, markersize=4)
            
            # ì‹¤ì œê°’ í”Œë¡¯ (ìˆëŠ” ê²½ìš°)
            actual_data = df.dropna(subset=['actual'])
            if len(actual_data) > 0:
                ax.plot(actual_data['date'], actual_data['actual'], 
                       marker='^', color='green', label='Actual', linewidth=2, markersize=4)
            
            ax.set_title(f"{window.upper()} Moving Average")
            ax.grid(True, linestyle='--', alpha=0.5)
            ax.legend()
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
        for i in range(n_windows, 4):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        
        # íŒŒì¼ ì €ì¥
        os.makedirs(save_prefix, exist_ok=True)
        filename = f"varmax_ma_analysis_{sequence_start_date}.png"
        filepath = os.path.join(save_prefix, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"VARMAX moving average analysis saved: {filepath}")
        return filepath
        
    except Exception as e:
        logger.error(f"Error creating VARMAX moving average analysis: {str(e)}")
        logger.error(traceback.format_exc())
        return None